\documentclass{IEEEtran}

\input{info.tex}
\input{packages.tex}

\begin{document}

\begin{section}{Introduction}
	With the significant advance in communication performance (throughput, latency, outage), the main challenge of wireless network has come to energy supply. Most existing mobile devices are powered by batteries that require frequent charging or replacement, which leads to high maintenance cost and restricts the scale of networks. Although solar energy and inductive coupling has become popular alternatives, the former depends on the environment while the latter has a very short operation range. Simultaneous Wireless Information and Power Transfer (SWIPT) is a promising solution to connect and power mobile devices via electromagnetic (EM) waves in the radio-frequency (RF) band. It provides low power (in \si{\uW} level) but broad coverage (up to hundreds of meters) \cite{Ng2018} in a sustainable and controllable manner. The trend of reduction in electronic power consumption also boosts the paradigm shift from dedicated power source to Wireless Power Transfer (WPT) and SWIPT.

	The concept of SWIPT were first cast in \cite{Varshney2008}, where the authors investigated the rate-energy (R-E) tradeoff for a flat Gaussian channel and some discrete channels. Two practical receiver structures were then proposed in \cite{Zhou2013}, namely Time Switching (TS) that switch between energy harvesting (EH) and Information Decoding (ID) modes and Power Splitting (PS) that splits the received signal into individual components. On top of this, \cite{Zhang2013} characterized the R-E region for a multiple-input multiple-output (MIMO) broadcast system under TS and PS setup. Information and power beamforming was then considered in multi-user multi-input single-output (MISO) systems to maximize the weighted sum-power subjective to SINR constraints \cite{Xu2014}. Motivated by this, \cite{Krikidis2014} investigated fundamental transceiver modules, information and power scheduling, and interference management for SWIPT systems. However, \cite{Boshkovska2015} pointed out that the Radio Frequency (RF)-to-Direct Current (DC) conversion efficiency depends on the harvester input power level. The authors also suggested a practical parametric harvester model based on curve fitting and proposed an iterative resource allocation algorithm. From another perspective, \cite{Trotter2009,Boaventura2011} demonstrated that multisine waveform outperforms single tone in both operation range and RF-to-DC efficiency, which is more suitable for WPT. In \cite{Clerckx2016a}, a tractable diode nonlinear model was derived based on the Taylor expansion of diode I-V characteristics and proposed an adaptive waveform optimization algorithm to maximize the output DC current. Simulation and experiments demonstrated the benefit of modelling rectifier nonlinearity in system design \cite{Kim2019,Kim2019a}. The work was extended to SWIPT in \cite{Clerckx2018} where a superposition of modulated information waveform and multisine power waveform is optimized to enlarge the R-E region. In contrast, \cite{Park2018} suggested an adaptive dual-mode SWIPT alternating between single-tone transmission that exploits conventional modulation for high-rate applications and multisine transmission that boosts the energy while encoding the information in the Peak-to-Average Ratio (PAPR) for power-demanding applications. Assuming On-Off-Keying (OOK) where bit 1 carries energy, \cite{Hu2019} compared unary and Run-Length-Limited (RLL) code in terms of rate vs battery overflow/underflow probability, and adjusted conventional modulation schemes such that WPT is only activated at the points with large offset. Also, a learning approach \cite{Varasteh2019c} demonstrated that the offset of the power symbol is positively correlated to the energy constraint, while the information symbols are symmetrically distributed around the origin. It confirmed that the superposed waveform is feasible to enlarge R-E region when considering rectifier nonlinearity. SWIPT was also applied in the network design of Non-Orthogonal Multiple Access (NOMA) and Rate-Splitting Multiple Access (RSMA). \cite{Liu2016} proposed a cooperative SWIPT NOMA protocol with three user selection schemes to enable the strong user assists the EH of the weak user. In \cite{Mao2019}, SWIPT was formulated as a Weighted-Sum Rate (WSR) maximization problem subject to total harvested energy constraint for separated Information Receivers (IRs) and Energy Receivers (ERs).

	Intelligent Reflecting Surface (IRS) adapts the wireless environment to increase spectrum and energy efficiency. A practical IRS consists of multiple individual elements that adjust the incident signal in terms of amplitude and phase through passive beamforming \cite{Wu2019e}. Different from relay and backscatter communication, it assists the primary transmission without any active components, leading to low power consumption and no thermal noise added to the reflected signal. IRS also contributes to a squared gain of the number of reflectors on the received signal power, which can be interpreted as a Maximum Ratio Combining (MRC) overlapped to a Maximum Ratio Transmission (MRT).
\end{section}

\begin{section}{System Model}
	Consider an IRS-aided multiuser SISO SWIPT system where the IRS not only assists the primal transmission but also retrieves Channel State Information (CSI) and harvests energy for its own operation. The single-antenna transmitter delivers information and power simultaneously, through the $L$-reflector IRS, to $K$ single-antenna users over $N$ orthogonal subbands. Assume a total bandwidth $B$ and evenly-spaced carriers around center frequency $f_0$. Denote the frequency of the $n$-th subband as $f_n$ ($n=1,\dots,N$). Suppose each subband is allocated to one user per time slot. It is assumed that the IRS performs channel estimation in the first subframe and supports information and power transfer in the second subframe \cite{Zheng2019}. Due to the passive characteristics of IRS, we consider a Time-Division Duplexing (TDD) protocol where the CSI can be obtained by exploiting channel reciprocity. Perfect CSI is assumed at the AP and IRS to investigate the analytical upper-bound of the proposed system. A quasi-static frequency-selective model is used for both the AP-user and AP-IRS-user links where the channels are assumed unchanged within each transmission frame. The signals reflected by IRS for two and more times are assumed negligible and thus not considered. Note that although Frequency Selective Surface (FSS) has received much attention for wideband communications, active FSS requires RF-chains thus becomes prohibitive in IRS \cite{Kim2006,Xu2014}. Since passive FSS is not reconfigurable with fixed physical characteristics \cite{Anwar2018}, we assume a frequency-flat IRS with the same reflection coefficients for all subbands. Since a deterministic multisine waveform can boost the energy transfer efficiency \cite{Clerckx2016a} and creates no interference to the information signal \cite{Clerckx2018b}, we use a superposition of multicarrier modulated and unmodulated waveforms, both transmitted on the same frequency bands, to maximize the rate-energy tradeoff. Two practical receiver architectures proposed in \cite{Zhang2013}, namely Time Switching (TS) and Power Splitting (PS), are investigated for the co-located information decoder and energy harvester. In the TS strategy, each transmission subframe is further divided into orthogonal data and energy slots, with duration ratio $(1-\lambda)$ and $\lambda$ respectively. Hence, the achievable rate-energy region can be obtained through a time sharing between wireless power transfer (WPT) with $\lambda=1$ and wireless information transfer (WIT) with $\lambda=0$. The adjustment of $\lambda$ has no impact on the transmit waveform and IRS elements design as they are optimized individually in data and energy slots. In comparison, the PS scheme splits the received signal into data and energy streams with power ratio $(1-\rho)$ and $\rho$ such that the PS ratio is coupled with waveform design. Perfect synchronization is assumed among the three parties in both scenarios.

	\begin{subsection}{Transmit Signal}
		Denote $\tilde{x}_{I,n}(t)$ as the information symbol transmitted over subband $n$, which belongs to one user at time $t$ and follows a capacity-achieving i.i.d. Circular Symmetric Complex Gaussian (CSCG) distribution $\tilde{x}_{I,n}\sim\mathcal{CN}(0,1)$. Let $\alpha_{k,n}$ be the allocation indicator, namely if subband $n$ is given to user $k$ ($k=1,\dots,K$), we have $\alpha_{k,n}=1$ and $\alpha_{k',n}=0 \ \forall k' \ne k$. Let $\boldsymbol{\alpha}_k=[\alpha_{k,1},\dots,\alpha_{k,N}]^T \in \mathbb{C}^{N \times 1}$. The superposed transmit signal at time $t$ is
		\begin{equation}\label{eq:x}
			x(t)=\Re\left\{\sum_{n=1}^N\left({w_{I,n}\tilde{x}_{I,n}(t)}+w_{P,n}\right){e^{j2{\pi}{f_n}{t}}}\right\}
		\end{equation}
		where $w_{I/P,n}=s_{I/P,n}e^{j\psi_{I/P,n}}$ collects the magnitude and phase of the information and power signal at frequency $n$. We further define the waveform vectors $\boldsymbol{w}_{I/P}=[w_{I/P,1},\dots,w_{I/P,N}]^T \in \mathbb{C}^{N{\times}1}$.
	\end{subsection}

	\begin{subsection}{Composite Channel Model}
		Denote the frequency response of the AP-user $k$ direct link as $\boldsymbol{h}_{D,k}=[h_{D,k,1},\dots,h_{D,k,N}]^T \in \mathbb{C}^{N \times 1}$. Let $[\boldsymbol{h}_{I,1},\dots,\boldsymbol{h}_{I,N}] \in \mathbb{C}^{L \times N}$ be the frequency response of AP-IRS incident channel, where $\boldsymbol{h}_{I,n} \in \mathbb{C}^{L \times 1}$ corresponds to the $n$-th incident channel. Similarly, let $[\boldsymbol{h}_{R,k,1},\dots,\boldsymbol{h}_{R,k,N}]^H \in \mathbb{C}^{N \times L}$ be the frequency response of IRS-user $k$ reflective channel, where $\boldsymbol{h}_{R,k,n}^H \in \mathbb{C}^{1 \times L}$ corresponds to the $n$-th reflective channel. At the IRS, element $l$ ($l=1,\dots,L$) redistributes the received signal by adjusting the amplitude reflection coefficient $\beta_l \in [0,1]$ and phase shift $\theta_l \in [0,2\pi)$ \footnote{To investigate the performance upper bound of IRS, we suppose the reflection coefficient is maximized $\beta_l=1 \ \forall l$ while the phase shift is a continuous variable over $[0,2\pi)$.}. On top of this, the IRS matrix is constructed by collecting the reflection coefficients onto the main diagonal entries as $\boldsymbol{\Theta} = \mathrm{diag}\left\{\beta_1 e^{j \theta_1}, \dots, \beta_L e^{j \theta_L}\right\} \in \mathbb{C}^{L \times L}$. The IRS-aided link can be modeled as a concatenation of the AP-IRS channel, IRS reflection, and IRS-user $k$ channel, which for user $k$ over subband $n$ is
		\begin{equation}\label{eq:h_{E,k,n}}
			h_{E,k,n} = \boldsymbol{h}_{R,k,n}^H \boldsymbol{\Theta} \boldsymbol{h}_{I,n} = \boldsymbol{v}_{k,n}^H \boldsymbol{\phi}
		\end{equation}
		where $\boldsymbol{v}_{k,n}^H=\boldsymbol{h}_{R,k,n}^H \mathrm{diag}(\boldsymbol{h}_{I,n}) \in \mathbb{C}^{1 \times L}$ and $\boldsymbol{\phi}=[e^{j{\theta_1}},\dots,e^{j{\theta_L}}] \in \mathbb{C}^{L \times 1}$. Both direct and extra link contributes to the corresponding composite channel as
		\begin{equation}
			h_{k,n} = A_{k,n} e^{j\bar{\psi}_{k,n}}= h_{D,k,n} + \boldsymbol{v}_{k,n}^H \boldsymbol{\phi}
		\end{equation}
		where $A_{k,n}$ and $\bar{\psi}_{k,n}$ are the amplitude and phase of the composite channel of user $k$ at subband $n$. Let $\boldsymbol{V}_k^H=[\boldsymbol{v}_{k,1},\dots,\boldsymbol{v}_{k,N}]^H \in \mathbb{C}^{N \times L}$, the extra link for user $k$ is $\boldsymbol{h}_{E,k}=[h_{E,k,1},\dots,h_{E,k,N}]^T=\boldsymbol{V}_k^H \boldsymbol{\phi} \in \mathbb{C}^{N \times 1}$. Therefore, the composite channel of user $k$ is
		\begin{equation}\label{eq:h_k}
			\boldsymbol{h}_k = \boldsymbol{h}_{D,k} + \boldsymbol{V}_k^H \boldsymbol{\phi}
		\end{equation}
	\end{subsection}

	\begin{subsection}{Receive Signal}
		The RF signal received by user $k$ captures the contribution of information and power waveforms through both direct and IRS-aided links as
		\begin{equation}\label{eq:y_k}
			y_k(t)=\Re\left\{\sum_{n=1}^N{h_{{k,n}}}\left({w_{I,n}\tilde{x}_{I,n}(t)}+w_{P,n}\right){e^{j2{\pi}{f_n}{t}}}\right\}
		\end{equation}
		which can be divided into
		\begin{align}\label{eq:y_{I/P,k}}
			y_{I,k}(t) & = \Re\left\{\sum_{n=1}^N{h_{{k,n}}}{w_{I,n}\tilde{x}_{I,n}(t)}{e^{j2{\pi}{f_n}{t}}}\right\}\\
			y_{P,k}(t) & = \Re\left\{\sum_{n=1}^N{h_{{k,n}}}w_{P,n}{e^{j2{\pi}{f_n}{t}}}\right\}
		\end{align}
	\end{subsection}

	\begin{subsection}{Information Decoder}
		% ? OFDM interference
		A major benefit of the superposed waveform is that the power component $y_{P,k}(t)$ creates no interference to the information component $y_{I,k}(t)$. Hence, the achievable rate of user $k$ is
		\begin{equation}\label{eq:R_k}
			R_k(\boldsymbol{w}_I,\boldsymbol{\phi},\rho,\boldsymbol{\alpha}_k)=\sum_{n=1}^N\alpha_{k,n}{\log_2\left(1+\frac{(1-\rho)\lvert h_{k,n}w_{I,n} \rvert^2}{\sigma_n^2}\right)}
		\end{equation}
		where $\sigma_n^2$ is the variance of the noise at RF band and during RF-to-BB conversion on tone $n$. Rate \ref{eq:R_k} is achievable with either waveform cancellation or translated demodulation \cite{Clerckx2018b}.
	\end{subsection}

	\begin{subsection}{Energy Harvester}
		Consider a nonlinear diode model based on the Taylor expansion of a small signal model \cite{Clerckx2016a,Clerckx2018b}, which highlights the dependency of harvester output DC current on the received waveform of user $k$ as
		\begin{equation}\label{eq:i_k}
			i_k(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\phi},\rho)\approx\sum_{i=0}^{\infty}{k_i'}{\rho^{i/2}}{R_{\text{ant}}^{i/2}}\mathcal{E}\left\{{\mathcal{A}\left\{y_k(t)^i\right\}}\right\}
		\end{equation}
		where $R_{\text{ant}}$ is the impedance of the receive antenna, $k_0'=i_s(e^{-i_kR_{\text{ant}}/nv_t}-1)$, $k_i'=i_se^{-i_kR_{\text{ant}}/nv_t}/i!(nv_t)^i$ for $i=1,\dots,\infty$, $i_s$ is saturation current, $n$ is diode ideality factor, $v_t$ is thermal voltage. For a fixed channel and waveform, $\mathcal{A}\left\{.\right\}$ extracts the DC component of the received signal while $\mathcal{E}\left\{.\right\}$ covers the expectation over $\tilde{x}_{I,n}$.

		With the assumption of evenly spaced frequencies, we have $\mathcal{E}\left\{y_k(t)^i\right\}=0 \ \forall i \ \mathrm{odd}$ such that the related terms has no contribution to DC components. For simplicity, we truncate the infinite series to the $n_0$-th order. Maximizing a truncated \ref{eq:i_k} is equivalent to maximizing a monotonic function \cite{Clerckx2016a}
		\begin{equation}\label{eq:z_k}
			z_k(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\phi},\rho)=\sum_{i\,\text{even},i\ge2}^{n_0}{k_i}{\rho^{i/2}}{R_{\text{ant}}^{i/2}}{\mathcal{E}\left\{\mathcal{A}\left\{y_k(t)^i\right\}\right\}}
		\end{equation}
		where $k_i=i_s/i!(nv_t)^i$. We choose $n_0=4$ to investigate the fundamental impact of diode nonlinearity on waveform design. Note that $\mathcal{E}\left\{\lvert\tilde{x}_{I,n}\rvert^2\right\}=1$ and $\mathcal{E}\left\{\lvert\tilde{x}_{I,n}\rvert^4\right\}=2$, which can be interpreted as a modulation gain on the nonlinear terms of the output DC current.

		For simplicity, we define $\boldsymbol{W}_{I/P}=\boldsymbol{w}_{I/P}\boldsymbol{w}_{I/P}^H$ and $\boldsymbol{H}_k=\boldsymbol{h}_k\boldsymbol{h}_k^H$ as waveform matrices and channel matrix of user $k$. Let $\boldsymbol{W}_{I/P,n}$, $\boldsymbol{H}_{k,n}$ keep the $n$-th ($n=-N+1,\dots,N-1$) diagonal of $\boldsymbol{W}_{I/P}$, $\boldsymbol{H}_k$ and null the remaining entries, respectively. Due to the positive definiteness of $\boldsymbol{W}_{I/P}$ and $\boldsymbol{H}_k$, we have $\boldsymbol{W}_{I/P,-n}=\boldsymbol{W}_{I/P,n}^H$ and $\boldsymbol{H}_{k,-n}=\boldsymbol{H}_{k,n}^H$. Let $\beta_2={k_2}{R_{\text{ant}}}$ and $\beta_4={k_4}{R_{\text{ant}}^2}$. On top of this, nonzero terms in \ref{eq:z_k} are detailed in \ref{eq:z_k_terms_begin} -- \ref{eq:z_k_terms_end} such that the current expression reduces to \ref{eq:z_k_expand} -- \ref{eq:z_k_waveform}.
		\begin{figure*}[b]
			\hrule
			\begin{align}
				\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}
				& = \frac{1}{2}\sum_n{(h_{k,n}w_{I,n})(h_{k,n}w_{I,n})^*}\label{eq:z_k_terms_begin}\\
				& = \frac{1}{2}\boldsymbol{h}_k^H\boldsymbol{W}_{I,0}^*\boldsymbol{h}_k = \frac{1}{2}\boldsymbol{w}_I^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_I\\
				\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^4(t)\right\}\right\}
				& = \frac{3}{4}\left(\sum_n{(h_{k,n}w_{I,n})(h_{k,n}w_{I,n})^*}\right)^2\\
				& = \frac{3}{4}(\boldsymbol{h}_k^H\boldsymbol{W}_{I,0}^*\boldsymbol{h}_k)^2 = \frac{3}{4}(\boldsymbol{w}_I^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_I)^2\\
				\mathcal{A}\left\{y_{P,k}^2(t)\right\}
				& = \frac{1}{2}\sum_n{(h_{k,n}w_{P,n})(h_{k,n}w_{P,n})^*}\\
				& = \frac{1}{2}\boldsymbol{h}_k^H\boldsymbol{W}_{P,0}^*\boldsymbol{h}_k = \frac{1}{2}\boldsymbol{w}_P^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_P\\
				\mathcal{A}\left\{y_{P,k}^4(t)\right\}
				& = \frac{3}{8}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{(h_{k,{n_1}}w_{P,{n_1}})(h_{k,{n_2}}w_{P,{n_2}})(h_{k,{n_3}}w_{P,{n_3}})^*(h_{k,{n_4}}w_{P,{n_4}})^*}\\
				& = \frac{3}{8}\sum_{n=-N+1}^{N-1}(\boldsymbol{h}_k^H\boldsymbol{W}_{P,n}^*\boldsymbol{h}_k)(\boldsymbol{h}_k^H\boldsymbol{W}_{P,n}^*\boldsymbol{h}_k)^* = \frac{3}{8}\sum_{n=-N+1}^{N-1}(\boldsymbol{w}_P^H\boldsymbol{H}_{k,n}^*\boldsymbol{w}_P)(\boldsymbol{w}_P^H\boldsymbol{H}_{k,n}^*\boldsymbol{w}_P)^*\label{eq:z_k_terms_end}
			\end{align}
		\end{figure*}
		\begin{figure*}[b]
			\hrule
			\begin{align}
				z_k(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\phi},\rho)
				& = \beta_2\rho\left(\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}+\mathcal{A}\left\{y_{P,k}^2(t)\right\}\right)+\beta_4\rho^2\left(\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^4(t)\right\}\right\}+\mathcal{A}\left\{y_{P,k}^4(t)\right\}+6\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}\mathcal{A}\left\{y_{P,k}^2(t)\right\}\right)\label{eq:z_k_expand}\\
				& = \frac{1}{2}\beta_2\rho(\boldsymbol{h}_k^H\boldsymbol{W}_{I,0}^*\boldsymbol{h}_k+\boldsymbol{h}_k^H\boldsymbol{W}_{P,0}^*\boldsymbol{h}_k)\nonumber\\
				& \quad+ \frac{3}{8}\beta_4\rho^2 \left(2(\boldsymbol{h}_k^H\boldsymbol{W}_{I,0}^*\boldsymbol{h}_k)^2 + \sum_{n=-N+1}^{N-1} (\boldsymbol{h}_k^H\boldsymbol{W}_{P,n}^*\boldsymbol{h}_k)(\boldsymbol{h}_k^H\boldsymbol{W}_{P,n}^*\boldsymbol{h}_k)^*\right)\nonumber\\
				& \quad+ \frac{3}{2}\beta_4\rho^2(\boldsymbol{h}_k^H\boldsymbol{W}_{I,0}^*\boldsymbol{h}_k)(\boldsymbol{h}_k^H\boldsymbol{W}_{P,0}^*\boldsymbol{h}_k)\label{eq:z_k_channel}\\
				& = \frac{1}{2}\beta_2\rho(\boldsymbol{w}_I^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_I+\boldsymbol{w}_P^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_P)\nonumber\\
				& \quad+ \frac{3}{8}\beta_4\rho^2 \left(2(\boldsymbol{w}_I^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_I)^2 + \sum_{n=-N+1}^{N-1}(\boldsymbol{w}_P^H\boldsymbol{H}_{k,n}^*\boldsymbol{w}_P)(\boldsymbol{w}_P^H\boldsymbol{H}_{k,n}^*\boldsymbol{w}_P)^* \right)\nonumber\\
				& \quad+ \frac{3}{2}\beta_4\rho^2(\boldsymbol{w}_I^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_I)(\boldsymbol{w}_P^H\boldsymbol{H}_{k,0}^*\boldsymbol{w}_P)\label{eq:z_k_waveform}
			\end{align}
		\end{figure*}
	\end{subsection}

	\begin{subsection}{Weighted Sum Rate-Energy Region}
		Define the achievable weighted sum rate-energy (WSR-E) region as
		\begin{equation}
			\begin{split}
				C_{R-I}(P)
				&\triangleq \biggl\{(R,I):R\le\sum_{k=1}^K{u_{I,k}R_k},I\le\sum_{k=1}^K u_{P,k}z_k,\\
				&\quad \frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P}) \le P\biggr\}
			\end{split}
		\end{equation}
		where $P$ is the transmit power budget and $u_{I,k},u_{P,k}$ are the information and power weight of user $k$.
	\end{subsection}
\end{section}

\begin{section}{Single-User Optimization}
	Consider a single-user waveform and IRS optimization problem where $\boldsymbol{\alpha}=\boldsymbol{1}^{N \times 1}$. We characterize the rate-energy region through a current maximization problem subject to transmit power, rate, and IRS constraints
	\begin{maxi!}
			{\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\phi},\rho}{z(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\phi},\rho)}{\label{op:su}}{}
			\addConstraint{\frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P})\le{P}}
			\addConstraint{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert(h_{D,n}+\boldsymbol{v}_n^H\boldsymbol{\phi})w_{I,n}\rvert^2}{\sigma_n^2}\right)} \ge \bar{R}}
			\addConstraint{\lvert{\phi_l}\rvert=1, \quad l=1,\dots,L}
		\end{maxi!}
	Problem \ref{op:su} is intricate due to the non-convex objective function with coupled variables. In the next section, we propose two waveform and phase shift design algorithms for frequency-flat and frequency-selective IRS, respectively.

	\begin{subsection}{Frequency-Selective IRS}
		Each element in frequency-selective IRS is expected to provide subband-dependent reflection coefficients. Hence, $\boldsymbol{\phi}_n$ replaces $\boldsymbol{\phi}$ in \ref{op:su} and the IRS has a total degree of freedom (DoF) of $NL$. Note that $\lvert{(h_{D,n}+\boldsymbol{v}_n^H\boldsymbol{\phi}_n)w_{I,n}}\rvert \le \lvert{h_{D,n}w_{I,n}}\rvert+\lvert{\boldsymbol{v}_n^H\boldsymbol{\phi}_n w_{I,n}}\rvert$ where the equality holds when the direct and IRS-aided links are aligned. Therefore, we choose the phase shift of element $l$ at subband $n$ as
		\begin{equation}\label{eq:theta}
			\theta_{n,l}^\star = \angle{h}_{D,n} - \angle{h_{R,n,l}}-\angle{h_{I,n,l}}
		\end{equation}
		That is to say, the optimal phase shift is obtained in closed form in the single-user scenario, and the phase of the composite channel equals that of the direct channel. Moreover, it can be observed from \ref{eq:R_k} and \ref{eq:z_k_expand} that the optimal phases of information and power waveform are both match to the composite channel as
		\begin{equation}\label{eq:psi}
			\psi_{I,n}^{\star}=\psi_{P,n}^{\star}=-\bar{\psi}_{n}
		\end{equation}
		By such a phase selection, we have
		\begin{equation}
			\lvert{(h_{D,n}+\boldsymbol{v}_n^H\boldsymbol{\phi}_n)w_{I,n}}\rvert = \lvert h_{D,n} \rvert \lvert w_{I,n} \rvert + \vert \boldsymbol{v}_n^H\boldsymbol{\phi}_n \rvert \lvert w_{I,n} \rvert
		\end{equation}
		Therefore, the original problem \ref{op:su} is reduced to an waveform magnitude optimization problem
		\begin{maxi!}
				{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho}{z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}{\label{op:su_gp}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P})\le{P}}
				\addConstraint{\sum_{n}{\log_2\left(1+\frac{(1-\rho){A_n^2}{s_{I,n}^2}}{\sigma_n^2}\right)} \ge \bar{R}}
			\end{maxi!}
		\begin{figure*}[b]
			\hrule
			\begin{equation}\label{eq:z_gp}
				\begin{split}
					z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)
					&=\frac{1}{2}{\beta_2}{\rho}\sum_n{A_n^2(s_{I,n}^2+s_{P,n}^2)}\\
					&\quad+\frac{3}{8}{\beta_4}{\rho^2} \left(\left(\sum_{n}(A_n s_{I,n})(A_n s_{I,n})^*\right)^2 + \sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{A_{n_1}A_{n_2}A_{n_3}A_{n_4}(s_{P,n_1}s_{P,n_2}s_{P,n_3}s_{P,n_4})}\right)\\
					&\quad+\frac{3}{2}{\beta_4}{\rho^2}\sum_n{{A_n^4}{s_{I,n}^2}{s_{P,n}^2}}
				\end{split}
			\end{equation}
		\end{figure*}
		with $z$ given by \ref{eq:z_gp}. We introduce an auxiliary variable $t''$ and transform problem \ref{op:su_gp} into
		\begin{mini!}
				{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho,t''}{\frac{1}{t''}}{\label{op:su_gp_1}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P}) \le P}
				\addConstraint{\frac{t''}{z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)} \le 1}
				\addConstraint{\frac{2^{\bar{R}}}{\prod_n \left(1+\frac{(1-\rho){A_n^2}{s_{I,n}^2}}{\sigma_n^2}\right)} \le 1}
			\end{mini!}
		Problem \ref{op:su_gp_1} is a Reversed Geometric Program which can be transformed to standard Geometric Program (GP). The idea is to decompose the information and power posynomials as sum of monomials, then derive their upper bounds using Arithmetic Mean-Geometric Mean (AM-GM) inequality \cite{Clerckx2018b,Chiang2005}. Let $z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)=\sum_{m=1}^{M}{g_{P,m}(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}$, problem \ref{op:su_gp_1} is equivalent to
		\begin{mini}
			{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho,\bar{\rho},t''}{\frac{1}{t''}}{\label{op:su_gp_2}}{}
			\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P})\le{P}}
			\addConstraint{{t''}\prod_m{\left(\frac{g_{P,m}(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}{\gamma_{P,m}}\right)^{-\gamma_{P,m}}}\le{1}}
			\addConstraint{2^{\bar{R}}\prod_{n}{\left(\frac{1}{\gamma_{I,n,1}}\right)^{-\gamma_{I,n,1}} \left(\frac{\bar{\rho}{A_n^2}{s_{I,n}^2}}{{\sigma_n^2}{\gamma_{I,n,2}}}\right)^{-\gamma_{I,n,2}}}\le{1}}
			\addConstraint{\rho + \bar{\rho} \le 1}
		\end{mini}
		where $\gamma_{I,n,1},\gamma_{I,n,2} \ge 0$, $\gamma_{I,n,1}+\gamma_{I,n,2}=1$, $\gamma_{P,m} \ge 0 \ \forall m$, and $\sum_{m=1}^{M}{\gamma_m}=1$. The tightness of the AM-GM inequality depends on $\{\gamma_{I,n},\gamma_P\}$ that require successive update. At iteration $i$, we choose \cite{Clerckx2018b}
		\begin{align}
			\gamma_{I,n,1}^{(i)} & = \left. 1 \middle/ \left(1+\frac{\bar{\rho}^{(i-1)}{A_n^2}(s_{I,n}^{(i-1)})^2}{\sigma_n^2}\right) \right.\label{eq:gamma_I_1}\\
			\gamma_{I,n,2}^{(i)} & = 1 - \gamma_{I,n,1}^{(i)}\label{eq:gamma_I_2}\\
			\gamma_{P,m}^{(i)} & =\frac{g_{P,m}(\boldsymbol{s}_I^{(i-1)},\boldsymbol{s}_P^{(i-1)},\rho^{(i-1)})}{z(\boldsymbol{s}_I^{(i-1)},\boldsymbol{s}_P^{(i-1)},\rho^{(i-1)})}\label{eq:gamma_P}
		\end{align}
		and then solve problem \ref{op:su_gp_2}. The algorithm is summarized in Algorithm \ref{al:fs_waveform}.
		\begin{algorithm}
			\caption{FS-IRS: Waveform Amplitude Optimization}
			\label{al:fs_waveform}
			\begin{algorithmic}[1]
				\State \textbf{Input} $P, \bar{R}, \theta_l \ \forall l$
				\State \textbf{Initialize} $i \leftarrow 0$, $\boldsymbol{s}_{I/P}^{(0)}$, $\rho^{(0)}, \boldsymbol{h}$ by \ref{eq:h_k}, \ref{eq:theta}
				\Repeat
				\State $i \leftarrow i + 1$
				\State Update GM exponents $\{\gamma_{I,n}^{(i)},\gamma_{P}^{(i)}\}$ by \ref{eq:gamma_I_1} -- \ref{eq:gamma_P}
				\State Obtain waveform amplitude $\boldsymbol{s}_{I/P}^{(i)}$ and splitting ratio $\rho^{(i)}, \bar{\rho}^{(i)}$ by solving problem \ref{op:su_gp_2}
				\State Compute output DC current $z^{(i)}$ by \ref{eq:z_gp}
				\Until $\lvert z^{(i)} - z^{(i-1)} \rvert \le \epsilon$
				\State \textbf{Output} $\boldsymbol{s}_{I/P}^{\star}, \rho^{\star}, z^{\star}$
			\end{algorithmic}
		\end{algorithm}
	\end{subsection}

	\begin{subsection}{Frequency-Flat IRS}
		In contrast, frequency-flat IRS reflects all subbands equally with a DoF of $L$. We observe that
		\begin{equation}
			\begin{split}
				\lvert{h_{D,n}+\boldsymbol{v}_n^H\boldsymbol{\phi}}\rvert^2
				&=\lvert{h_{D,n}}\rvert^2+h_{D,n}^*\boldsymbol{v}_n^H\boldsymbol{\phi}+\boldsymbol{\phi}^H\boldsymbol{v}_n{h_{D,n}}+\boldsymbol{\phi}^H\boldsymbol{v}\boldsymbol{v}^H\boldsymbol{\phi}\\
				&=\bar{\boldsymbol{\phi}}^H\boldsymbol{R}_n\bar{\boldsymbol{\phi}}=\mathrm{Tr}(\boldsymbol{R}_n\bar{\boldsymbol{\phi}}\bar{\boldsymbol{\phi}}^H)=\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{\Phi})
			\end{split}
		\end{equation}
		where $t$ is an auxiliary variable with unit modulus and
		\begin{equation}
			\boldsymbol{R}_n=
			\begin{bmatrix}
				\boldsymbol{v}_n\boldsymbol{v}_n^H & \boldsymbol{v}_n{h_{D,n}} \\
				h_{D,n}^*{\boldsymbol{v}_n^H}      & h_{D,n}^*{h_{D,n}}
			\end{bmatrix},
			\quad \bar{\boldsymbol{\phi}}=\
			\begin{bmatrix}
				\boldsymbol{\phi} \\
				t
			\end{bmatrix},
			\quad \boldsymbol{\Phi}=\bar{\boldsymbol{\phi}}\bar{\boldsymbol{\phi}}^H
		\end{equation}
		with $\boldsymbol{R}_n,\boldsymbol{\Phi} \in \mathbb{C}^{(L+1) \times (L+1)}$ and $\bar{\boldsymbol{\phi}} \in \mathbb{C}^{(L+1) \times 1}$. On top of this, the outer product of composite channel rewrites as
		\begin{equation}
			\boldsymbol{h}\boldsymbol{h}^H=\boldsymbol{M}^H\boldsymbol{\Phi}\boldsymbol{M}
		\end{equation}
		where $\boldsymbol{M}=[\boldsymbol{V}^H,\boldsymbol{h}_D]^H \in \mathbb{C}^{(L+1) \times N}$. To reduce the design complexity, we propose an suboptimal alternating optimization algorithm that iteratively updates the phase shifts and the waveforms with the other being fixed.

		\begin{subsubsection}{Phase shift optimization}\label{se:fs_irs}
			The phase optimization subproblem is formed as follows. With a given waveform $\boldsymbol{w}_I,\boldsymbol{w}_P,\rho$, introduce auxiliary variables
			\begin{equation}\label{eq:t}
				\begin{split}
					t_{I/P,n}
					&=\boldsymbol{h}^H\boldsymbol{W}_{I/P,n}^*\boldsymbol{h}\\
					&=\mathrm{Tr}(\boldsymbol{h}\boldsymbol{h}^H\boldsymbol{W}_{I/P,n}^*)\\
					&=\mathrm{Tr}(\boldsymbol{M}^H\boldsymbol{\Phi}\boldsymbol{M}\boldsymbol{W}_{I/P,n}^*)\\
					&=\mathrm{Tr}(\boldsymbol{M}\boldsymbol{W}_{I/P,n}^*\boldsymbol{M}^H\boldsymbol{\Phi})\\
					&=\mathrm{Tr}(\boldsymbol{C}_{I/P,n}\boldsymbol{\Phi})
				\end{split}
			\end{equation}
			where we define $\boldsymbol{C}_{I/P,n}=\boldsymbol{M}\boldsymbol{W}_{I/P,n}^*\boldsymbol{M}^H \in \mathbb{C}^{(L+1)\times(L+1)}$. Therefore, \ref{eq:z_k_channel} rewrites as
			\begin{equation}\label{eq:z_irs}
				\begin{split}
					z(\boldsymbol{\Phi})
					&=\frac{1}{2}{\beta_2}{\rho}(t_{I,0}+t_{P,0})\\
					&\quad+\frac{3}{8}{\beta_4}{\rho^2} \left(2t_{I,0}^2 + \sum_{n=-N+1}^{N-1}{t_{P,n}t_{P,n}^*}\right)\\
					&\quad+\frac{3}{2}{\beta_4}{\rho^2}t_{I,0}t_{P,0}
				\end{split}
			\end{equation}
			We use first-order Taylor expansion to approximate the second-order terms in \ref{eq:z_irs}. Based on the variables optimized at iteration $i - 1$, the local approximation at iteration $i$ suggests \cite{Adali2010}
			\begin{align}
				(t_{I,0}^{(i)})^2
				& \ge 2 (t_{I,0}^{(i)})(t_{I,0}^{(i-1)}) - (t_{I,0}^{(i-1)})^2\nonumber\\
				& = 2 \mathrm{Tr}(t_{I,0}^{(i-1)}\boldsymbol{C}_{I,0}\boldsymbol{\Phi}^{(i)}) - (t_{I,0}^{(i-1)})^2\label{eq:t_approx_begin}\\
				t_{P,n}^{(i)} (t_{P,n}^{(i)})^*
				& \ge 2 \Re\left\{t_{P,n}^{(i)} (t_{P,n}^{(i-1)})^*\right\} - t_{P,n}^{(i-1)} (t_{P,n}^{(i-1)})^*\nonumber\\
				& = 2 \Re \left\{\mathrm{Tr}\left((t_{P,n}^{(i-1)})^*\boldsymbol{C}_{P,n}\boldsymbol{\Phi}^{(i)}\right)\right\} - t_{P,n}^{(i-1)} (t_{P,n}^{(i-1)})^*\nonumber\\
				& = \mathrm{Tr}\left((t_{P,n}^{(i-1)})^*\boldsymbol{C}_{P,n}\boldsymbol{\Phi}^{(i)}\right) + \mathrm{Tr}\left(t_{P,n}^{(i-1)}\boldsymbol{C}_{P,n}^H\boldsymbol{\Phi}^{(i)}\right)\nonumber\\
				& \quad- t_{P,n}^{(i-1)} (t_{P,n}^{(i-1)})^*\\
				t_{I,0}^{(i)} t_{P,0}^{(i)}
				& = \frac{1}{4}(t_{I,0}^{(i)} + t_{P,0}^{(i)})^2 - \frac{1}{4}(t_{I,0}^{(i)} - t_{P,0}^{(i)})^2\nonumber\\
				& \ge \frac{1}{2}(t_{I,0}^{(i-1)} + t_{P,0}^{(i-1)})(t_{I,0}^{(i)} + t_{P,0}^{(i)})\nonumber\\
				& \quad - \frac{1}{4}(t_{I,0}^{(i-1)} + t_{P,0}^{(i-1)})^2 - \frac{1}{4}(t_{I,0}^{(i)} - t_{P,0}^{(i)})^2\label{eq:t_approx_end}
				% & \approx t_{I,0}^{(i)} t_{P,0}^{(i-1)} + t_{I,0}^{(i-1)} t_{P,0}^{(i)} - t_{I,0}^{(i-1)} t_{P,0}^{(i-1)}\nonumber\\
				% & = \mathrm{Tr}(t_{P,0}^{(i-1)}\boldsymbol{C}_{I,0}\boldsymbol{\Phi}^{(i)}) + \mathrm{Tr}(t_{I,0}^{(i-1)}\boldsymbol{C}_{P,0}\boldsymbol{\Phi}^{(i)})\nonumber\\
				% & \quad - t_{I,0}^{(i-1)} t_{P,0}^{(i-1)}\label{eq:t_approx_3}
			\end{align}
			\ref{eq:t_approx_begin} -- \ref{eq:t_approx_end} provide lower bounds to corresponding terms such that the approximated current function at iteration $i$ is
			\begin{equation}\label{eq:z_irs_approx}
				\begin{split}
					\tilde{z}(\boldsymbol{\Phi}^{(i)})
					& = \mathrm{Tr}(\boldsymbol{A}^{(i)}\boldsymbol{\Phi}^{(i)})\\
					& \quad + \frac{1}{2}(t_{I,0}^{(i-1)} + t_{P,0}^{(i-1)})(t_{I,0}^{(i)} + t_{P,0}^{(i)}) - \frac{1}{4}(t_{I,0}^{(i)} - t_{P,0}^{(i)})^2\\
					& \quad - \frac{3}{8} \beta_4 \rho^2 \left(2 (t_{I,0}^{(i-1)})^2 + \sum_{n=-N+1}^{N-1} t_{P,n}^{(i-1)} (t_{P,n}^{(i-1)})^* \right)\\
					& \quad - \frac{1}{4}(t_{I,0}^{(i-1)} + t_{P,0}^{(i-1)})^2
				\end{split}
			\end{equation}
			where the corresponding Hermitian matrix $\boldsymbol{A}^{(i)}$ is
			\begin{equation}\label{eq:A}
				\begin{split}
					\boldsymbol{A}^{(i)}
					& = \frac{1}{2} \beta_2 \rho (\boldsymbol{C}_{I,0}+\boldsymbol{C}_{P,0})\\
					& \quad+ \frac{3}{8} \beta_4 \rho^2 \Biggl(4 t_{I,0}^{(i-1)} \boldsymbol{C}_{I,0}\\
					& \quad \quad + \sum_{n=-N+1}^{N-1} (t_{P,n}^{(i-1)})^*\boldsymbol{C}_{P,n} + t_{P,n}^{(i-1)}\boldsymbol{C}_{P,n}^H \Biggl)
					% & \quad+ \frac{3}{2} \beta_4 \rho^2 (t_{P,0}^{(i-1)}\boldsymbol{C}_{I,0} + t_{I,0}^{(i-1)}\boldsymbol{C}_{P,0})
				\end{split}
			\end{equation}
			Hence, problem \ref{op:su} is transformed to
			\begin{maxi!}
				{\boldsymbol{\boldsymbol{\Phi}}}{\tilde{z}(\boldsymbol{\Phi})}{\label{op:su_irs}}{\label{eq:su_irs_target}}
				\addConstraint{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert{w}_{I,n}\rvert^2\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{\Phi})}{\sigma_n^2}\right)} \ge \bar{R}}
				\addConstraint{\boldsymbol{\Phi}_{l,l}=1, \quad l=1,\dots,L+1}
				\addConstraint{\boldsymbol{\Phi}\succeq{0}}
				\addConstraint{\mathrm{rank}(\boldsymbol{\Phi})=1\label{co:irs_rank}}
			\end{maxi!}
			We then relax the rank constraint \ref{co:irs_rank} and solve the optimal IRS matrix $\boldsymbol{\Phi}^{\star}$ iteratively by interior-point method. If $\mathrm{rank}(\boldsymbol{\Phi}^{\star})=1$, the optimal phase shift vector $\bar{\boldsymbol{\phi}}^\star$ is attained by eigenvalue decomposition (EVD). Otherwise, a best feasible candidate $\bar{\boldsymbol{\phi}}^\star$ can be extracted through Gaussian randomization method \cite{Huang2010}. First, perform EVD on $\boldsymbol{\Phi}^{\star}$ as $\boldsymbol{\Phi}^{\star}=\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}^H$. Then, we generate $Q$ CSCG random vectors $\boldsymbol{r}_q \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{L+1}),\ q=1,\dots,Q$ and construct the corresponding candidates $\bar{\boldsymbol{\phi}}_q=e^{j\arg\left(\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_q\right)}$. Next, the optimal solution $\bar{\boldsymbol{\phi}}^\star$ is approximated by the one achieving maximum objective value \ref{eq:su_irs_target}. Finally, we can retrieve the phase shift by $\theta_l=\arg(\phi_l^\star/\phi_{L+1}^\star), \ l=1,\dots,L$. The algorithm for the phase optimization subproblem is summarized in Algorithm \ref{al:ff_irs}.
			\begin{algorithm}
				\caption{FF-IRS: Phase Shift Optimization}
				\label{al:ff_irs}
				\begin{algorithmic}[1]
					\State \textbf{Input} $\bar{R},Q,\boldsymbol{w}_I,\boldsymbol{w}_P,\rho,\boldsymbol{R}_n,\boldsymbol{C}_{I/P,n},\sigma_n \ \forall n$
					\State \textbf{Initialize} $i \leftarrow 0,\boldsymbol{\Phi}^{(0)},t_{I/P,n}^{(0)}\ \forall n$ by \ref{eq:t}
					\Repeat
					\State $i \leftarrow i + 1$
					\State Update SDR matrix $\boldsymbol{A}^{(i)}$ by \ref{eq:A}
					\State Obtain IRS matrix $\boldsymbol{\Phi}^{(i)}$ by solving problem \ref{op:su_irs}
					\State Update auxiliary $t_{I/P,n}^{(i)} \forall n$ by \ref{eq:t} for SCA
					\Until $\lvert z^{(i)}-z^{(i-1)} \rvert \le \epsilon$
					\State Perform EVD $\boldsymbol{\Phi}^{\star}=\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}^H$
					\State Generate random vectors $\boldsymbol{r}_q \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{L+1}) \ \forall q$
					\State Construct candidate IRS vectors $\bar{\boldsymbol{\phi}}_q=e^{j\arg\left(\boldsymbol{U}_{\boldsymbol{\Phi}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_q\right)}$ and matrices $\boldsymbol{\Phi}_q=\bar{\boldsymbol{\phi}}_q\bar{\boldsymbol{\phi}}_q^H  \ \forall q$
					\State Select best solution $\boldsymbol{\Phi}^\star$ and $\boldsymbol{\phi}^\star$ for problem \ref{op:su_irs}
					\State Compute phase shift by $\theta_l=\arg(\phi_l^\star/\phi_{L+1}^\star), \ l=1,\dots,L$
					\State \textbf{Output} $\theta_l, \ l=1,\dots,L$
				\end{algorithmic}
			\end{algorithm}
		\end{subsubsection}

		\begin{subsubsection}{Waveform optimization}
			Consider the waveform optimization subproblem. Once $\boldsymbol{\Phi}$ is obtained, introduce auxiliary variables
			\begin{equation}\label{eq:t'}
				t_{I/P,n}' = \boldsymbol{w}_{I/P}^H \boldsymbol{H}_n^* \boldsymbol{w}_{I/P} = \mathrm{Tr}(\boldsymbol{H}_n^*\boldsymbol{W}_{I/P})
			\end{equation}
			Therefore, \ref{eq:z_k_waveform} rewrites as
			\begin{equation}\label{eq:z_waveform}
				\begin{split}
					z(\boldsymbol{W}_I,\boldsymbol{W}_P,\rho)
					&=\frac{1}{2} \beta_2 \rho (t'_{I,0}+t'_{P,0})\\
					&\quad+\frac{3}{8} \beta_4 \rho^2 \left(2(t'_{I,0})^2 + \sum_{n=-N+1}^{N-1}{t'_{P,n}(t'_{P,n})^*}\right)\\
					&\quad+\frac{3}{2} \beta_4 \rho^2 t'_{I,0}t'_{P,0}
				\end{split}
			\end{equation}
			Similar to \ref{eq:t_approx_begin} -- \ref{eq:t_approx_end}, the coupled terms at iteration $i$ are approximated as
			\begin{align}
				(\rho^{(i)} t_{I,0}^{\prime (i)})^2
				& \ge 2 \mathrm{Tr}\left(\rho^{(i-1)}t_{I,0}^{\prime (i-1)}\rho^{(i)}\boldsymbol{H}_{0}^*\boldsymbol{W}_{I}^{(i)}\right)\nonumber\\
				& \quad - (\rho^{(i-1)}t_{I,0}^{\prime (i-1)})^2\\
				(\rho^{(i)})^2 t_{P,n}^{\prime (i)} (t_{P,n}^{\prime (i)})^*
				& \ge \mathrm{Tr}\left(\rho^{(i-1)}(t_{P,n}^{\prime (i-1)})^*\rho^{(i)}\boldsymbol{H}_{n}^*\boldsymbol{W}_{P}^{(i)}\right)\nonumber\\
				& \quad + \mathrm{Tr}\left(\rho^{(i-1)}t_{P,n}^{\prime (i-1)}\rho^{(i)}\boldsymbol{H}_{n}^T\boldsymbol{W}_{P}^{(i)}\right)\nonumber\\
				& \quad - (\rho^{(i-1)})^2 t_{P,n}^{\prime (i-1)} (t_{P,n}^{\prime (i-1)})^*\\
				(\rho^{(i)})^2
				& \ge 2\rho^{(i-1)}\rho^{(i)} - (\rho^{(i-1)})^2\nonumber\\
				& \triangleq a^{(i)}\label{eq:a}\\
				t_{I,0}^{\prime (i)} t_{P,0}^{\prime (i)}
				& \ge \frac{1}{2} (t_{I,0}^{\prime (i-1)} + t_{P,0}^{\prime (i-1)})(t_{I,0}^{\prime (i)} + t_{P,0}^{\prime (i)})\nonumber\\
				& \quad - \frac{1}{4}(t_{I,0}^{\prime (i-1)}+t_{P,0}^{\prime (i-1)})^2 - \frac{1}{4}(t_{I,0}^{\prime (i)} - t_{P,0}^{\prime (i)})^2\nonumber\\
				& \triangleq b^{(i)}\label{eq:b}
				% & \approx t_{I,0}^{\prime (i)} t_{P,0}^{\prime (i-1)} + t_{I,0}^{\prime (i-1)} t_{P,0}^{\prime (i)} - t_{I,0}^{\prime (i-1)} t_{P,0}^{\prime (i-1)}\nonumber\\
				% & = \mathrm{Tr}(t_{P,0}^{\prime (i-1)}\boldsymbol{H}_{0}^*\boldsymbol{W}_{I}^{(i)}) + \mathrm{Tr}(t_{I,0}^{\prime (i-1)}\boldsymbol{H}_{0}^*\boldsymbol{W}_{P}^{(i)})\nonumber\\
				% & \quad - t_{I,0}^{\prime (i-1)} t_{P,0}^{\prime (i-1)}
			\end{align}
			Therefore, the approximated current function at iteration $i$ is
			\begin{equation}\label{eq:z_waveform_approx}
				\begin{split}
					% \tilde{z}(\boldsymbol{W}_I^{(i)},\boldsymbol{W}_P^{(i)},\rho^{(i)})
					\tilde{z}^{(i)}
					& = \rho^{(i)}\left(\mathrm{Tr}(\boldsymbol{A}_I^{(i)}\boldsymbol{W}_I^{(i)}) + \mathrm{Tr}(\boldsymbol{A}_P^{(i)}\boldsymbol{W}_P^{(i)})\right) + a^{(i)} b^{(i)}\\
					& \quad - \frac{3}{8} \beta_4 (\rho^{(i-1')})^2 \left(2 (t_{I,0}^{\prime (i-1)})^2 + \sum_{n=-N+1}^{N-1} t_{P,n}^{\prime (i-1)} (t_{P,n}^{\prime (i-1)})^*\right)
					% & \quad - \frac{3}{2} \beta_4 t_{I,0}^{\prime (i-1)} t_{P,0}^{\prime (i-1)}
				\end{split}
			\end{equation}
			where the Hermitian matrices $\boldsymbol{A}_I^{(i)}$ and $\boldsymbol{A}_P^{(i)}$ are
			\begin{align}
				\boldsymbol{A}_I^{(i)}
				& = \frac{1}{2} \beta_2 \boldsymbol{H}_0^* + \frac{3}{2} \beta_4 \rho^{(i-1)} t_{I,0}^{\prime (i-1)} \boldsymbol{H}_{0}^*\label{eq:A_I}\\
				\boldsymbol{A}_P^{(i)}
				& = \frac{1}{2} \beta_2 \boldsymbol{H}_0^* + \frac{3}{8} \beta_4 \rho^{(i-1)} \sum_{n=-N+1}^{N-1} (t_{P,n}^{\prime (i-1)})^*\boldsymbol{H}_{n}^* + t_{P,n}^{\prime (i-1)}\boldsymbol{H}_{n}^T\label{eq:A_P}
				% & \quad + \frac{3}{2} \beta_4 t_{I,0}^{\prime (i-1)}\boldsymbol{H}_{0}^*\label{eq:A_P}
			\end{align}
			\begin{figure*}[b]
				\hrule
				\begin{align}
					\tilde{z}'^{(i)}
					& = \frac{1}{2}\left(\rho^{(i-1)} + \mathrm{Tr}(\boldsymbol{A}_{I}^{(i-1)}\boldsymbol{W}_{I}^{(i-1)})\right)\left(\rho^{(i)} + \mathrm{Tr}(\boldsymbol{A}_{I}^{(i)}\boldsymbol{W}_{I}^{(i)})\right) - \frac{1}{4}\left(\rho^{(i-1)} + \mathrm{Tr}(\boldsymbol{A}_{I}^{(i-1)}\boldsymbol{W}_{I}^{(i-1)})\right)^2 - \frac{1}{4}\left(\rho^{(i)} - \mathrm{Tr}(\boldsymbol{A}_{I}^{(i)}\boldsymbol{W}_{I}^{(i)})\right)^2\nonumber\\
					& \quad + \frac{1}{2}\left(\rho^{(i-1)} + \mathrm{Tr}(\boldsymbol{A}_{P}^{(i-1)}\boldsymbol{W}_{P}^{(i-1)})\right)\left(\rho^{(i)} + \mathrm{Tr}(\boldsymbol{A}_{P}^{(i)}\boldsymbol{W}_{P}^{(i)})\right) - \frac{1}{4}\left(\rho^{(i-1)} + \mathrm{Tr}(\boldsymbol{A}_{P}^{(i-1)}\boldsymbol{W}_{P}^{(i-1)})\right)^2 - \frac{1}{4}\left(\rho^{(i)} - \mathrm{Tr}(\boldsymbol{A}_{P}^{(i)}\boldsymbol{W}_{P}^{(i)})\right)^2\nonumber\\
					& \quad + \frac{1}{2}(\bar{a}^{(i-1)} + \bar{b}^{(i-1)})(\bar{a}^{(i)} + \bar{b}^{(i)}) - \frac{1}{4}(\bar{a}^{(i-1)} + \bar{b}^{(i-1)})^2 - \frac{1}{4}(\bar{a}^{(i)} - \bar{b}^{(i)})^2\label{eq:z_waveform_lb}\\
					g_n^{(i)}
					& = \frac{1}{2}\left((1-\rho^{(i-1)}) + W_{I,n,n}^{(i-1)}\right)\left((1-\rho^{(i)}) + W_{I,n,n}^{(i)}\right) - \frac{1}{4}\left((1-\rho^{(i-1)}) + W_{I,n,n}^{(i-1)}\right)^2 - \frac{1}{4}\left((1-\rho^{(i)}) - W_{I,n,n}^{(i)}\right)^2\label{eq:r_power_lb}
				\end{align}
			\end{figure*}
			% A lower bound of \label{eq:z_waveform_approx} is further provided in \ref{eq:z_waveform_lb}. Hence, problem \ref{op:su} is transformed to
			Hence, problem \ref{op:su} is transformed to
			\begin{maxi!}
				{\boldsymbol{W}_I,\boldsymbol{W}_P,\rho}{\tilde{z}(\boldsymbol{W}_I,\boldsymbol{W}_P,\rho)}{\label{op:su_waveform_1}}{\label{eq:su_waveform_target}}
				\addConstraint{\sum_{n}{\log_2\left(1+\frac{(1-\rho)W_{I,n,n}\lvert h_n \rvert^2}{\sigma_n^2}\right)} \ge \bar{R}\label{eq:su_waveform_constraint_1}}
				\addConstraint{\frac{1}{2}\left(\mathrm{Tr}(\boldsymbol{W}_I)+\mathrm{Tr}(\boldsymbol{W}_P)\right) \le P}
				\addConstraint{\boldsymbol{W}_{I/P} \succeq 0}
				\addConstraint{\mathrm{rank}(\boldsymbol{W}_{I/P})=1\label{co:waveform_rank}}
			\end{maxi!}
			Note that \ref{op:su_waveform_1} involves bilinear terms $\rho\mathrm{Tr}(\boldsymbol{A}_{I/P}\boldsymbol{W}_{I/P})$ and $(1-\rho)W_{I,n,n}$. We lower bound the objective function \ref{eq:su_waveform_target} and constraint \ref{eq:su_waveform_constraint_1} in \ref{eq:z_waveform_lb} and \ref{eq:r_power_lb} such that $\tilde{z}' \le \tilde{z}$ and $g_n(\rho,W_{I,n,n}) \le (1-\rho)W_{I,n,n}$. Therefore, problem \ref{op:su_waveform_1} is equivalent to
			\begin{maxi!}
				{\boldsymbol{W}_I,\boldsymbol{W}_P,\rho,\bar{a},\bar{b}}{\tilde{z}'(\boldsymbol{W}_I,\boldsymbol{W}_P,\rho)}{\label{op:su_waveform}}{}
				\addConstraint{\sum_{n}{\log_2\left(1+\frac{g_n(\rho,W_{I,n,n})\lvert h_n \rvert^2}{\sigma_n^2}\right)} \ge \bar{R}}
				\addConstraint{\frac{1}{2}\left(\mathrm{Tr}(\boldsymbol{W}_I)+\mathrm{Tr}(\boldsymbol{W}_P)\right) \le P}
				\addConstraint{\boldsymbol{W}_{I/P} \succeq 0}
				\addConstraint{\mathrm{rank}(\boldsymbol{W}_{I/P})=1}
				\addConstraint{a \ge \bar{a}}
				\addConstraint{b \ge \bar{b}}
			\end{maxi!}
			We then perform SDR and solve the optimal waveform matrix $\boldsymbol{W}_{I/P}^{\star}$ iteratively by interior-point method. $\boldsymbol{w}_I^{\star}$ and $\boldsymbol{w}_P^{\star}$ can also be extracted using randomized vectors $\boldsymbol{r}_q \in \mathbb{C}^{(L+1) \times 1}, \ q=1,\dots,Q$, whose entries are uniformly distributed on the unit circle $r_{q,n}=e^{j\omega}, \omega \in [0,2\pi]$. The algorithm is summarized in Algorithm \ref{al:fs_waveform}.

			\begin{algorithm}
				\caption{Waveform Optimization}
				\label{alg:waveform}
				\begin{algorithmic}[1]
					\State \textbf{Input} $\bar{R},P,Q,\boldsymbol{R}_n,\sigma_n \ \forall n$
					\State \textbf{Initialize} $i \leftarrow 0$, $\boldsymbol{W}_{I/P}^{(0)}$, $\rho^{(0)}$, $a^{(0)}$, $b^{(0)}$, $t_{I/P,n}^{\prime (0)} \ \forall n$
					\Repeat
					\State $i \leftarrow i + 1$
					\State Update SDR matrices $\boldsymbol{A}_{I/P}^{(i)}$ by \ref{eq:A_I} and \ref{eq:A_P}
					\State Obtain waveform matrices $\boldsymbol{W}_{I/P}^{(i)}$ and power splitting ratio $\rho^{(i)}$ by solving problem \ref{op:su_waveform}
					\State Update auxiliary $t_{I/P,n}^{\prime (i)} \forall n$ by \ref{eq:t'} for SCA
					\State Update auxiliary $a^{(i)},b^{(i)}$ by \ref{eq:a} and \ref{eq:b}
					\Until $\lvert z^{(i)}-z^{(i-1)} \rvert \le \epsilon$
					\State Perform EVD $\boldsymbol{W}_{I/P}^{\star}=\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}^H$
					\State Generate random vectors $\boldsymbol{r}_q \ \forall q$ with entries uniformly distributed on the unit circle
					\State Construct candidate waveform vectors $\boldsymbol{w}_{I/P,r}=\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{W}_{I/P}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_q$ and matrices $\boldsymbol{W}_{I/P,q}=\boldsymbol{w}_{I/P,q}\boldsymbol{w}_{I/P,q}^H  \ \forall q$
					\State Select the best solution $\boldsymbol{W}_{I}^\star,\boldsymbol{W}_{P}^\star$ and $\boldsymbol{w}_{I}^\star, \boldsymbol{w}_{P}^\star$ for problem \ref{op:su_waveform}
					\State \textbf{Output} $\boldsymbol{w}_I^\star, \boldsymbol{w}_P^\star, \rho^\star$
				\end{algorithmic}
			\end{algorithm}
		\end{subsubsection}

		\begin{subsection}{WIT initialization}
			To characterize the R-E region, we initialize the algorithm to WIT mode and reduce the rate constraint gradually to obtain the boundary points. Consider a rate maximization problem with given information waveform $\boldsymbol{w}_I$ as
			\begin{maxi!}
				{\boldsymbol{\Phi}}{\sum_{n}{\log_2\left(1+\frac{\lvert{w}_{I,n}\rvert^2\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{\Phi})}{\sigma_n^2}\right)}}{\label{op:su_irs_wit}}{}
				\addConstraint{\boldsymbol{\Phi}_{l,l}=1, \quad l=1,\dots,L+1}
				\addConstraint{\boldsymbol{\Phi}\succeq{0}}
				\addConstraint{\mathrm{rank}(\boldsymbol{\Phi})=1}
			\end{maxi!}
			Problem \ref{op:su_irs_wit} can be solved after SDR. Similar to section \ref{se:fs_irs}, a best solution $\bar{\boldsymbol{\phi}}^\star$ can be obtained via Gaussian randomization method and $\boldsymbol{\phi}^\star$ can be recovered by $\phi_l^\star=\phi_l^\star/\phi_{L+1}^\star, \ l=1,\dots,L$. After constructing composite channel by \ref{eq:h_k}, we use water-filling algorithm and matched filter to obtain optimal power allocation $p_n=\lvert w_{I,n} \rvert^2$ and waveform phase $\psi_{I,n}^\star=-\bar{\psi}_n$, respectively. Therefore, the optimal information waveform at subband $n$ is
			\begin{equation}\label{eq:w_wit}
				w_{I,n}=\sqrt{p_n}e^{j \psi_{I,n}^\star}
			\end{equation}
			We update IRS and information waveform iteratively by \ref{op:su_irs_wit} and \ref{eq:w_wit} until convergence. The WIT algorithm is summarized in \ref{alg:wit}.
			\begin{algorithm}
				\caption{WIT Initialization}
				\label{alg:wit}
				\begin{algorithmic}[1]
					\State \textbf{Input} $P, Q, \boldsymbol{R}_n, \sigma_n \ \forall n$
					\State \textbf{Initialize} $i \leftarrow 0$, $\boldsymbol{w}_I^{(0)}$, $t_{I/P,n}^{\prime (0)} \ \forall n$
					\Repeat
					\State $i \leftarrow i + 1$
					\State Obtain IRS matrix $\boldsymbol{\Phi}^{(i)}$ by solving problem \ref{op:su_irs_wit}
					\State Perform EVD $\boldsymbol{\Phi}^{(i)}=\boldsymbol{U}_{\boldsymbol{\Phi}^{(i)}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{(i)}}\boldsymbol{U}_{\boldsymbol{\Phi}^{(i)}}^H$
					\State Generate random vectors $\boldsymbol{r}_q \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{L+1}) \ \forall q$
					\State Construct candidate IRS vectors $\bar{\boldsymbol{\phi}}_q=e^{j\arg\left(\boldsymbol{U}_{\boldsymbol{\Phi}^{(i)}}\boldsymbol{\Sigma}_{\boldsymbol{\Phi}^{(i)}}^{\frac{1}{2}}\boldsymbol{r}_q\right)}$ and matrices $\boldsymbol{\Phi}_q=\bar{\boldsymbol{\phi}}_q\bar{\boldsymbol{\phi}}_q^H  \ \forall q$
					\State Select best solution $(\boldsymbol{\Phi}^{(i)})^\star$ and $(\boldsymbol{\phi}^{(i)})^\star$ for problem \ref{op:su_irs_wit}
					\State Update composite channel $\boldsymbol{h}^{(i)}$ by \ref{eq:h_k}
					\State Obtain optimal power allocation $p_n^{(i)} \ \forall n$ by water-filling algorithm
					\State Obtain optimal waveform phase $\psi_{I,n}^{(i)} \ \forall n$ by \ref{eq:psi}
					\State Update information waveform $\boldsymbol{w}_I^{(i)}$ by \ref{eq:w_wit}
					\Until $\lvert R^{(i)}-R^{(i-1)} \rvert \le \epsilon$
					\State \textbf{Output} $\boldsymbol{w}_I^\star, \boldsymbol{w}_P^\star, \boldsymbol{\phi}^\star$
				\end{algorithmic}
			\end{algorithm}
		\end{subsection}
	\end{subsection}
\end{section}

\bibliographystyle{IEEEtran}
\bibliography{library.bib}
\end{document}
