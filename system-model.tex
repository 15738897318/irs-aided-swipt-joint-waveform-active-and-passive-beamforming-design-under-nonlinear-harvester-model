\documentclass{IEEEtran}

\input{info.tex}
\input{packages.tex}

\begin{document}

\begin{section}{System Model}
	Consider an IRS-aided multiuser SISO SWIPT system where the IRS not only assists the primal transmission but also retrieves Channel State Information (CSI) and harvests energy for its own operation. The single-antenna transmitter delivers information and power simultaneously, through the $L$-reflector IRS, to $K$ single-antenna users over $N$ orthogonal subbands. It is assumed that the IRS performs channel estimation in the first subframe and supports information and power transfer in the second subframe \cite{Zheng2019}. Due to the passive characteristics of IRS, we consider a Time-Division Duplexing (TDD) protocol where the CSI can be obtained by exploiting channel reciprocity. Perfect CSI is assumed at the AP and IRS to investigate the analytical upper-bound of the proposed system. The signals reflected by IRS for two and more times are assumed negligible and thus not considered. A quasi-static frequency-selective model is used for both the AP-user and AP-IRS-user links where the channels are assumed unchanged within each transmission frame. A superposition of multicarrier modulated and unmodulated waveforms, both transmitted on the same frequency bands, are designed adaptively to maximize the rate-energy tradeoff \cite{Clerckx2018b}. Note that although Frequency Selective Surface (FSS) has received much attention for wideband communications, active FSS requires RF-chains thus becomes prohibitive in IRS \cite{Kim2006,Xu2014}. Since passive FSS is not reconfigurable with fixed physical characteristics \cite{Anwar2018}, we assume a frequency-flat IRS with same reflection coefficients for all subbands. Two practical receiver architectures proposed in \cite{Zhang2013}, namely Time Switching (TS) and Power Splitting (PS), are investigated for the co-located information decoder and energy harvester. In the TS strategy, each transmission subframe is further divided into orthogonal data and energy slots with duration ratio $(1-\alpha)$ and $\alpha$ respectively. Hence, the achievable rate-energy region can be obtained through a direct time sharing between wireless power transfer (WPT) with $\alpha=1$ and wireless information transfer (WIT) with $\alpha=0$. The adjustment of $\alpha$ has no impact on the transmit waveform and IRS elements design, since they are optimized individually in data and energy slots. In comparison, the PS scheme splits the received signal into data and energy streams with power ratio $(1-\rho)$ and $\rho$. As $\rho$ is coupled with waveform and IRS design, we investigate the rate-energy region by placing different rate constraints and optimizing waveform, PS ratio and reflectors accordingly. Perfect synchronization is assumed among the three parties in both scenario.

	\begin{subsection}{Transmitted Signal}
		\begin{subsubsection} {Modulated Information Waveform}
			Assume the carrier are evenly spaced with equal bandwidth $B_s$ such that the frequency of the $n$-th subband is $f_n=f_0+(n-1){\Delta}{f}$ ($n=1,\dots,N$). The information symbol $\tilde{x}_{I,k,n}\sim\mathcal{CN}(0,1)$ of user $k$ over subband $n$ is a capacity-achieving i.i.d. Circular Symmetric Complex Gaussian (CSCG) variable with zero mean and unit variance. Therefore, the baseband (BB) transmit information signal at subband $n$ can be expressed as
			\begin{equation}\label{eq:x_{I,n}(t)}
				x_{I,n}(t)=\sum_{k=1}^K{w_{I,k,n}\tilde{x}_{I,k,n}(t)}
			\end{equation}
			where $w_{I,k,n}$ is the corresponding information weight. Let $\boldsymbol{W}_I=[\boldsymbol{w}_{I,1},\dots,\boldsymbol{w}_{I,N}]^T \in \mathbb{C}^{N \times K}$ with $\boldsymbol{w}_{I,n}=[w_{I,1,n},\dots,w_{I,K,n}]^T \in \mathbb{C}^{K \times 1}$. On top of this, the overall frequency weight is denoted as $w_{I,n}=\sum_k{w_{I,k,n}}$ and collected into $\boldsymbol{w}_I=[w_{I,1},\dots,w_{I,N}]^T \in \mathbb{C}^{N \times 1}$. The RF transmit information waveform at time $t$ writes as
			% Let $\boldsymbol{W}_I=[\boldsymbol{w}_{I,1},\dots,\boldsymbol{w}_{I,N}]=[\boldsymbol{w}_{I,1}^T,\dots,\boldsymbol{w}_{I,K}^T]^T \in \mathbb{C}^{K \times N}$ with $\boldsymbol{w}_{I,n}=[w_{I,1,n},\dots,w_{I,K,n}]^T \in \mathbb{C}^{K \times 1}$ and $\boldsymbol{w}_{I,k}=[w_{I,k,1},\dots,w_{I,k,N}] \in \mathbb{C}^{1 \times N}$.
			% Let $\boldsymbol{W}_I=[\boldsymbol{w}_{I,1},\dots,\boldsymbol{w}_{I,N}] \in \mathbb{C}^{K \times N}$ with $\boldsymbol{w}_{I,n}=[w_{I,1,n},\dots,w_{I,K,n}]^T \in \mathbb{C}^{K \times 1}$.
			\begin{equation}\label{eq:x_I(t)}
				\begin{split}
					x_I(t)
					&=\sum_{n=1}^N{x_{I,n}(t){e^{j2{\pi}{f_n}{t}}}}\\
					&=\sum_{k=1}^K\sum_{n=1}^N{w_{I,k,n}\tilde{x}_{I,k,n}(t){e^{j2{\pi}{f_n}{t}}}}
					% &=\Re\left\{\sum_{n=1}^N{x_{I,n}(t){e^{j2{\pi}{f_n}{t}}}}\right\}\\
					% &=\Re\left\{\sum_{k=1}^K\sum_{n=1}^N{w_{I,k,n}\tilde{x}_{I,k,n}(t){e^{j2{\pi}{f_n}{t}}}}\right\}
				\end{split}
			\end{equation}
		\end{subsubsection}

		\begin{subsubsection}{Unmodulated Power Waveform}
			As suggested in \cite{Clerckx2018b,Clerckx2016a}, we use deterministic multisine waveform to boost the harvested energy. It has no randomness over time such that the baseband transmit power signal at subband $n$ is
			\begin{equation}\label{eq:x_{P,n}}
				x_{P,n}=\sum_{k=1}^K{w_{P,k,n}}
			\end{equation}
			where $w_{P,k,n}$ is the corresponding power weight. Let $\boldsymbol{W}_P=[\boldsymbol{w}_{P,1},\dots,\boldsymbol{w}_{P,N}]^T \in \mathbb{C}^{N \times K}$ with $\boldsymbol{w}_{P,n}=[w_{P,1,n},\dots,w_{P,K,n}]^T \in \mathbb{C}^{K \times 1}$. Similarly, the overall frequency weight is denoted as $w_{P,n}=\sum_k{w_{P,k,n}}$ and collected into $\boldsymbol{w}_P=[w_{P,1},\dots,w_{P,N}]^T \in \mathbb{C}^{N \times 1}$. The transmit power signal at time $t$ is given by
			% Let $\boldsymbol{W}_P=[\boldsymbol{w}_{P,1},\dots,\boldsymbol{w}_{P,N}]=[\boldsymbol{w}_{P,1}^T,\dots,\boldsymbol{w}_{P,K}^T]^T \in \mathbb{C}^{K \times N}$ with $\boldsymbol{w}_{P,n}=[w_{P,1,n},\dots,w_{P,K,n}]^T \in \mathbb{C}^{K \times 1}$ and $\boldsymbol{w}_{P,k}=[w_{P,k,1},\dots,w_{P,k,N}] \in \mathbb{C}^{1 \times N}$.
			\begin{equation}\label{eq:x_P(t)}
				\begin{split}
					x_P(t)
					&=\sum_{n=1}^N{x_{P,n}{e^{j2{\pi}{f_n}{t}}}}\\
					&=\sum_{k=1}^K\sum_{n=1}^N{w_{P,k,n}{e^{j2{\pi}{f_n}{t}}}}
					% &=\Re\left\{\sum_{n=1}^N{x_{P,n}{e^{j2{\pi}{f_n}{t}}}}\right\}\\
					% &=\Re\left\{\sum_{k=1}^K\sum_{n=1}^N{w_{P,k,n}{e^{j2{\pi}{f_n}{t}}}}\right\}
				\end{split}
			\end{equation}
		\end{subsubsection}

		\begin{subsubsection}{Superposed Waveform}
			At time $t$, a superposition of the information and power waveform at subband $n$ writes as
			\begin{equation}\label{eq:x_n(t)}
				x_n(t)=\sum_{k=1}^K{(w_{I,k,n}\tilde{x}_{I,k,n}(t)+w_{P,k,n}){e^{j2{\pi}{f_n}{t}}}}
			\end{equation}
			Hence, the transmitted RF signal is
			\begin{equation}\label{eq:x(t)}
				x(t)=\sum_{k=1}^K\sum_{n=1}^N{(w_{I,k,n}\tilde{x}_{I,k,n}(t)+w_{P,k,n}){e^{j2{\pi}{f_n}{t}}}}
				% x(t)=\Re\left\{\sum_{k=1}^K\sum_{n=1}^N{(w_{I,k,n}\tilde{x}_{I,k,n}(t)+w_{P,k,n}){e^{j2{\pi}{f_n}{t}}}}\right\}
			\end{equation}
		\end{subsubsection}
	\end{subsection}

	\begin{subsection}{Composite Channel Model}
		Denote the baseband equivalent channels from the AP to users, from the AP to the IRS, and from the IRS to users as $\boldsymbol{H}_D \in \mathbb{C}^{K \times N}$, $\boldsymbol{H}_I' \in \mathbb{C}^{L \times N}$, and $\boldsymbol{H}_R^H \in \mathbb{C}^{K \times NL}$ respectively. At subband $n$, the frequency response of direct and reflective links write as $\boldsymbol{h}_{D,n}=[h_{D,1,n},\dots,h_{D,K,n}]^H \in \mathbb{C}^{K \times 1}$ and $\boldsymbol{H}_{R,n}^H=[\boldsymbol{h}_{R,1,n},\dots,\boldsymbol{h}_{R,K,n}]^H \in \mathbb{C}^{K \times L}$ with $\boldsymbol{h}_{R,k,n}^H=[h_{R,k,n,1},\dots,h_{R,k,n,L}] \in \mathbb{C}^{1 \times L}$. Similarly, the $n$-th incident channel is given by $\boldsymbol{h}_{I,n}=[h_{I,n,1},\dots,h_{I,n,L}]^H \in \mathbb{C}^{L \times 1}$. To decouple the impact of IRS operation on the incident link, we construct a block-diagonal matrix $\boldsymbol{H}_I \triangleq \mathrm{diag}\left\{\boldsymbol{h}_{I,1},\dots,\boldsymbol{h}_{I,N}\right\} \in \mathbb{C}^{NL \times N}$. Element $l$ of the IRS receives a superposed waveform through the multipath channel, then redistributes it by adjusting the amplitude reflection coefficient $\beta_l \in [0,1]$ and phase shift $\theta_l \in [0,2\pi)$. Each passive reflector absorbs a small portion ($1 - \beta_l$) of the signal to support CSI decoding and impedance matching. On top of this, the IRS matrix per subband is constructed by collecting the reflection coefficients onto its diagonal entries as $\boldsymbol{\Theta}_0 = \mathrm{diag}\left\{\beta_1 e^{j \theta_1}, \dots, \beta_L e^{j \theta_L}\right\} \in \mathbb{C}^{L \times L}$. Finally, the IRS matrix is formed by $\boldsymbol{\Theta} = \mathrm{diag}\{\underbrace{\boldsymbol{\Theta}_0,\dots,\boldsymbol{\Theta}_0}_{N\text{ times}}\} \in \mathbb{C}^{NL \times NL}$. The IRS-aided extra link can be modeled as a concatenation of the AP-IRS channel, the IRS reflection matrix, and the IRS-user channel. Both direct and IRS-aided link contributes to the composite channel $\boldsymbol{H} \in \mathbb{C}^{K \times N}$ as
		\begin{equation}\label{eq:H}
			\boldsymbol{H} = \boldsymbol{H}_D+\boldsymbol{H}_R^H\boldsymbol{\Theta}\boldsymbol{H}_I
		\end{equation}
		whose $(k,n)$-th entry
		\begin{equation}\label{eq:h_{k,n}}
			h_{k,n}=h_{D,k,n}+\boldsymbol{h}_{R,k,n}^H\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n}
		\end{equation}
		represents the overall channel gain of user $k$ at subband $n$. On top of this, the $n$-th subchannel for all users $\boldsymbol{h}_n \in \mathbb{C}^{K \times 1}$ can be expressed as
		% We further define $\boldsymbol{h}_{k,n}=[\underbrace{h_{k,n},\dots,h_{k,n}}_{N\text{ times}}]^T \in \mathbb{C}^{K \times 1}$.s
		\begin{equation}\label{eq:h_n}
			\boldsymbol{h}_n=\boldsymbol{h}_{D,n}+\boldsymbol{H}_{R,n}^H\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n}
		\end{equation}
		Define $\boldsymbol{v}=[e^{j{\theta_1}},\dots,e^{j{\theta_L}}]^H \in \mathbb{C}^{L \times 1}$ and $\boldsymbol{\Phi}_n^H=\boldsymbol{H}_{R,n}^H\mathrm{diag}\left\{\boldsymbol{h}_{I,n}\right\} \in \mathbb{C}^{K \times L}$. Therefore, \ref{eq:h_n} rewrites as
		\begin{equation}
			\boldsymbol{h}_n=\boldsymbol{h}_{D,n}+\boldsymbol{\Phi}_n^H\boldsymbol{v}
		\end{equation}
	\end{subsection}

	\begin{subsection}{Received Signal}
		The RF signal received by user $k$ captures the contribution of information and power waveforms through both direct and reflective links as
		\begin{equation}\label{eq:y_k(t)}
			y_k(t)=\sum_{j=1}^K\sum_{n=1}^N{h_{k,n}}(w_{I,j,n}\tilde{x}_{I,j,n}+w_{P,j,n}){e^{j2{\pi}{f_n}{t}}}
		\end{equation}
		with the information and power components of
		\begin{equation}\label{eq:y_{I,k}(t)}
			y_{I,k}(t)=\sum_{j=1}^K\sum_{n=1}^N{h_{k,n}w_{I,j,n}\tilde{x}_{I,j,n}}{e^{j2{\pi}{f_n}{t}}}
		\end{equation}
		\begin{equation}\label{eq:y_{P,k}(t)}
			y_{P,k}(t)=\sum_{j=1}^K\sum_{n=1}^N{h_{k,n}w_{P,j,n}}{e^{j2{\pi}{f_n}{t}}}
		\end{equation}

	\end{subsection}

	\begin{subsection}{Information Decoder}
		One major benefit of using proposed waveform is that the deterministic power term $y_{P,k}(t)$ bears no information and creates no interference to the modulated information term $y_{I,k}(t)$. Hence, each user treats the information signals from other users as interference such that the SINR at subband $n$ of user $k$ is
		\begin{equation}\label{eq:gamma_{k,n}}
			\gamma_{k,n}=\frac{(1-\rho)(h_{k,n}w_{I,k,n})(h_{k,n}w_{I,k,n})^*}{\sum_{j=1,j{\ne}k}^K{(1-\rho)(h_{k,n}w_{I,j,n})(h_{k,n}w_{I,j,n})^*+\sigma_n^2}}
		\end{equation}
		where $\sigma_n^2$ is the sum variance of the Gaussian noise at the RF-band and those introduced during the RF-to-BB conversion on subband $n$. Therefore, the achievable rate of user $k$ is expressed as
		\begin{equation}\label{eq:R_k}
			R_k(\boldsymbol{W}_I,\boldsymbol{\Theta}_0,\rho)=\sum_{n=1}^N{\log_2(1+\gamma_{k,n})}
		\end{equation}
		A significant conclusion in \cite{Clerckx2018b} indicates that the rate \ref{eq:R_k} is always achievable with or without waveform cancellation, through either subtracting the determaxistic power component or constructing a translated codebook.
	\end{subsection}

	\begin{subsection}{Energy Harvester}
		Note that the information and power component $y_{I,k}(t)$ and $y_{P,k}(t)$ have different influence on the output DC current. Consider a nonlinear diode model based on the Taylor expansion of a small signal model \cite{Clerckx2018b,Clerckx2016a}, which highlights the dependency of the harvester output DC current on the received waveform as
		\begin{equation}\label{eq:i_k}
			i_k\approx\sum_{i=0}^{\infty}{k_i'}{\rho^{i/2}}{R_{\text{ant}}^{i/2}}\mathcal{E}\left\{{\mathcal{A}\left\{y_k(t)^i\right\}}\right\}
		\end{equation}
		where $R_{\text{ant}}$ is the impedance of the receive antenna, $k_0'=i_s(e^{-i_kR_{\text{ant}}/nv_t}-1)$, $k_i'=i_se^{-i_kR_{\text{ant}}/nv_t}/i!(nv_t)^i$ for $i=1,\dots,\infty$, $i_s$ is saturation current, $n$ is diode ideality factor, $v_t$ is thermal voltage. Once the composite channel response $h_{k,n}$ is fixed, the corresponding information and power weight $w_{I,k,n}$, $w_{P,k,n}$ are thus optimized such that the randomness comes from the input distribution $\tilde{x}_{k,n}$. Therefore, we first extract the DC component based on $h_{k,n}$, $w_{I,k,n}$, $w_{P,k,n}$ by $\mathcal{A}\left\{.\right\}$ and then take the expectation over $\tilde{x}_{k,n}$ by $\mathcal{E}\left\{.\right\}$. With the assumption of evenly spaced frequencies, $\mathcal{E}\left\{y^i(t)\right\}=0$ for odd $i$ and the related terms has zero contribution to DC components. \cite{Clerckx2016a} also demonstrated that to maximize $i_k$, it suffices to maximize the monotonic target function truncated to the $n_0$ order
		\begin{equation}\label{eq:z_k}
			z_k(\boldsymbol{W}_I,\boldsymbol{W}_P,\boldsymbol{\Theta}_0,\rho)=\sum_{i\,\text{even},i\ge2}^{n_0}{k_i}{\rho^{i/2}}{R_{\text{ant}}^{i/2}}{\mathcal{E}\left\{\mathcal{A}\left\{y_k(t)^i\right\}\right\}}
		\end{equation}
		where $k_i=i_s/i!(nv_t)^i$. We take $n_0=4$ to investigate the fundamental impact of diode nonlinearity on power transfer. Note that $\mathcal{E}\{\mathcal{A}\{y_{I,k}(t)y_{P,k}(t)\}\}=\mathcal{E}\{\mathcal{A}\{y_{I,k}^3(t)y_{P,k}(t)\}\}=\mathcal{E}\{\mathcal{A}\{y_{I,k}(t)y_{P,k}^3(t)\}\}=0$, $\mathcal{E}\{\mathcal{A}\{y_{I,k}^2(t)y_{P,k}^2(t)\}\}=\mathcal{A}\{\mathcal{E}\{y_{I,k}^2(t)\}\}\mathcal{A}\{y_{P,k}^2(t)\}$, and the remaining terms are expressed by \ref{eq:E{A{y_{I,k}**2}}} -- \ref{eq:A{y_{P,k}**4'}}. It is noteworthy that modulation provides a power gain to the nonlinear terms in the output DC current as $\mathcal{E}\left\{\lvert\tilde{x}_{k,n}\rvert^2\right\}=1$ and $\mathcal{E}\left\{\lvert\tilde{x}_{k,n}\rvert^4\right\}=2$.
		\begin{figure*}[b]
			\hrule
			\begin{align}
				\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}
				 & =\frac{1}{2}\sum_{j_1,j_2}\sum_n{(h_{k,n}w_{I,j_1,n})(h_{k,n}w_{I,j_2,n})^*}\label{eq:E{A{y_{I,k}**2}}}                                                                                                                                                                        \\
				%  & =\frac{1}{2}\sum_n{{\boldsymbol{w}_{I,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{I,n}}}                                                                                                                                                                                                      \\
				 & =\frac{1}{2}\sum_n{h_{k,n}h_{k,n}^*{\boldsymbol{w}_{I,n}^H}{\boldsymbol{J}_{K}}{\boldsymbol{w}_{I,n}}}                                                                                                                                                                         \\
				%  & =\frac{1}{2}\sum_{j_1,j_2}\sum_n{\left[w_{I,j_1,n}(h_{D,k,n}+\boldsymbol{h}_{R,k,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})\right]\left[w_{I,j_2,n}(h_{D,n,k}+\boldsymbol{h}_{R,k,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})\right]^*}                                                                                                                        \\
				\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^4(t)\right\}\right\}
				 & =\frac{3}{4}\sum_{j_1,j_2,j_3,j_4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{(h_{k,{n_1}}w_{I,{j_1},{n_1}})(h_{k,{n_2}}w_{I,{j_2},{n_2}})(h_{k,{n_3}}w_{I,{j_3},{n_3}})^*(h_{k,{n_4}}w_{I,{j_4},{n_4}})^*}                       \\
				%  & = \frac{3}{4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{({\boldsymbol{w}_{I,n_3}^H}{\boldsymbol{h}_{k,n_3}^*}{\boldsymbol{h}_{k,n_1}^T}{\boldsymbol{w}_{I,n_1}})({\boldsymbol{w}_{I,n_4}^H}{\boldsymbol{h}_{k,n_4}^*}{\boldsymbol{h}_{k,n_2}^T}{\boldsymbol{w}_{I,n_2}})} \\
				 & =\frac{3}{4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{h_{k,n_3}^*h_{k,n_1}h_{k,n_4}^*h_{k,n_2}(\boldsymbol{w}_{I,n_3}^H\boldsymbol{J}_K\boldsymbol{w}_{I,n_1})(\boldsymbol{w}_{I,n_4}^H\boldsymbol{J}_K\boldsymbol{w}_{I,n_2})} \\
				%  & =\frac{3}{4}\sum_{j_1,j_2,j_3,j_4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}\left[w_{I,{j_1},{n_1}}(h_{D,k,n_1}+\boldsymbol{h}_{R,k,n_1}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_1})\right]\left[w_{I,{j_2},{n_2}}(h_{D,k,n_2}+\boldsymbol{h}_{R,k,n_2}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_2})\right]\nonumber \\
				%  & \quad\left[w_{I,{j_3},{n_3}}(h_{D,k,n_3}+\boldsymbol{h}_{R,k,n_3}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_3})\right]^*\left[w_{I,{j_4},{n_4}}(h_{D,k,n_4}+\boldsymbol{h}_{R,k,n_4}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_4})\right]^*                                                                                                                           \\
				\mathcal{A}\left\{y_{P,k}^2(t)\right\}
				 & =\frac{1}{2}\sum_{j_1,j_2}\sum_n{(h_{k,n}w_{P,j_1,n})(h_{k,n}w_{P,j_2,n})^*}                                                                                                                                                                                                   \\
				%  & = \frac{1}{2}\sum_n{{\boldsymbol{w}_{P,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{P,n}}}                                                                                                                                                                                                     \\
				 & =\frac{1}{2}\sum_n{h_{k,n}h_{k,n}^*{\boldsymbol{w}_{P,n}^H}{\boldsymbol{J}_{K}}{\boldsymbol{w}_{P,n}}}                                                                                                                                                                         \\
				%  & =\frac{1}{2}\sum_{j_1,j_2}\sum_n{\left[w_{P,j_1,n}(h_{D,k,n}+\boldsymbol{h}_{R,k,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})\right]\left[w_{P,j_2,n}(h_{D,k,n}+\boldsymbol{h}_{R,k,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})\right]^*}                                                                                                                        \\
				\mathcal{A}\left\{y_{P,k}^4(t)\right\}
				 & =\frac{3}{8}\sum_{j_1,j_2,j_3,j_4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{(h_{k,{n_1}}w_{P,{j_1},{n_1}})(h_{k,{n_2}}w_{P,{j_2},{n_2}})(h_{k,{n_3}}w_{P,{j_3},{n_3}})^*(h_{k,{n_4}}w_{P,{j_4},{n_4}})^*}                       \\
				%  & =\frac{3}{8}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{({\boldsymbol{w}_{P,n_3}^H}{\boldsymbol{h}_{k,n_3}^*}{\boldsymbol{h}_{k,n_1}^T}{\boldsymbol{w}_{P,n_1}})({\boldsymbol{w}_{P,n_4}^H}{\boldsymbol{h}_{k,n_4}^*}{\boldsymbol{h}_{k,n_2}^T}{\boldsymbol{w}_{P,n_2}})}  \\
				 & =\frac{3}{8}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{h_{k,n_3}^*h_{k,n_1}h_{k,n_4}^*h_{k,n_2}(\boldsymbol{w}_{P,n_3}^H\boldsymbol{J}_K\boldsymbol{w}_{P,n_1})(\boldsymbol{w}_{P,n_4}^H\boldsymbol{J}_K\boldsymbol{w}_{P,n_2})}
				\label{eq:A{y_{P,k}**4'}}
				%  & =\frac{3}{8}\sum_{j_1,j_2,j_3,j_4}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}\left[w_{P,{j_1},{n_1}}(h_{D,k,n_1}+\boldsymbol{h}_{R,k,n_1}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_1})\right]\left[w_{P,{j_2},{n_2}}(h_{D,k,n_2}+\boldsymbol{h}_{R,k,n_2}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_2})\right]\nonumber \\
				%  & \quad\left[w_{P,{j_3},{n_3}}(h_{D,k,n_3}+\boldsymbol{h}_{R,k,n_3}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_3})\right]^*\left[w_{P,{j_4},{n_4}}(h_{D,k,n_4}+\boldsymbol{h}_{R,k,n_4}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n_4})\right]^*\label{eq:A{y_{P,k}**4'}}
			\end{align}
		\end{figure*}
		Therefore, \ref{eq:z_k} reduces to \ref{eq:z_k_truncated}.
		\begin{figure*}[b]
			\hrule
			\begin{equation}\label{eq:z_k_truncated}
				\begin{split}
					% z_k(\boldsymbol{W}_I,\boldsymbol{W}_P,\boldsymbol{\Theta},\rho)
					z_k
					&={k_2}{\rho}{R_{\text{ant}}}\left(\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}+\mathcal{A}\left\{y_{P,k}^2(t)\right\}\right)+{k_4}{\rho^2}{R_{\text{ant}}^2}\left(\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^4(t)\right\}\right\}+\mathcal{A}\left\{y_{P,k}^4(t)\right\}+6\mathcal{E}\left\{\mathcal{A}\left\{y_{I,k}^2(t)\right\}\right\}\mathcal{A}\left\{y_{P,k}^2(t)\right\}\right)\\
					% &=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}\sum_n{{\boldsymbol{w}_{I,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{I,n}}+{\boldsymbol{w}_{P,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{P,n}}}\\
					% &\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{2({\boldsymbol{w}_{I,n_3}^H}{\boldsymbol{h}_{k,n_3}^*}{\boldsymbol{h}_{k,n_1}^T}{\boldsymbol{w}_{I,n_1}})({\boldsymbol{w}_{I,n_4}^H}{\boldsymbol{h}_{k,n_4}^*}{\boldsymbol{h}_{k,n_2}^T}{\boldsymbol{w}_{I,n_2}})+({\boldsymbol{w}_{P,n_3}^H}{\boldsymbol{h}_{k,n_3}^*}{\boldsymbol{h}_{k,n_1}^T}{\boldsymbol{w}_{P,n_1}})({\boldsymbol{w}_{P,n_4}^H}{\boldsymbol{h}_{k,n_4}^*}{\boldsymbol{h}_{k,n_2}^T}{\boldsymbol{w}_{P,n_2}})}\\
					% &\quad+\frac{3}{2}{k_4'}{\rho^2}{R_{\text{ant}}^2}\sum_n({\boldsymbol{w}_{I,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{I,n}})({\boldsymbol{w}_{P,n}^H}{\boldsymbol{h}_{k,n}^*}{\boldsymbol{h}_{k,n}^T}{\boldsymbol{w}_{P,n}})\\
					&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}\sum_n{h_{k,n}h_{k,n}^*(\boldsymbol{w}_{I,n}^H\boldsymbol{J}_{K}\boldsymbol{w}_{I,n}+\boldsymbol{w}_{P,n}^H\boldsymbol{J}_{K}\boldsymbol{w}_{P,n})}\\
					&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{h_{k,n_3}^*h_{k,n_1}h_{k,n_4}^*h_{k,n_2}\left(2(\boldsymbol{w}_{I,n_3}^H\boldsymbol{J}_K\boldsymbol{w}_{I,n_1})(\boldsymbol{w}_{I,n_4}^H\boldsymbol{J}_K\boldsymbol{w}_{I,n_2})+(\boldsymbol{w}_{P,n_3}^H\boldsymbol{J}_K\boldsymbol{w}_{P,n_1})(\boldsymbol{w}_{P,n_4}^H\boldsymbol{J}_K\boldsymbol{w}_{P,n_2})\right)}\\
					&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_n{h_{k,n}^2h_{k,n}^{*2}(\boldsymbol{w}_{I,n}^H\boldsymbol{J}_{K}\boldsymbol{w}_{I,n})(\boldsymbol{w}_{P,n}^H\boldsymbol{J}_{K}\boldsymbol{w}_{P,n})}
				\end{split}
			\end{equation}
		\end{figure*}
	\end{subsection}
\end{section}

\begin{section}{Problem Formulation}
	In this section, we first define the weighted sum rate-energy (WSR-E) region then formulate waveform and IRS optimization problems.
	\begin{subsection}{Weighted Sum Rate-Energy Region}
		We define the achievable WSR-E region as
		\begin{equation}
			\begin{split}
				C_{R-I}(P)
				&\triangleq \biggl\{(R,I):R\le\sum_{k=1}^K{u_{I,k}R_k},I\le\sum_{k=1}^K u_{P,k}z_k,\\
				&\quad \frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P}){\le}P\biggr\}
				% &\quad \frac{1}{2}\left(\Vert{\boldsymbol{W}_I}\Vert_F^2+\Vert{\boldsymbol{W}_P}\Vert_F^2\right){\le}P\biggr\}
			\end{split}
		\end{equation}
		where $u_{I,k},u_{P,k}$ denote the information and power weight of user $k$.
	\end{subsection}

	\begin{subsection}{Single-User Optimization}
		In this section, we first characterize the rate-energy region in the single-user setup. Let $h_n={A_n}{e^{j{\bar{\psi}_n}}}$, $w_{I,n}=s_{I,n}e^{j{\phi}_n}$, $w_{P,n}=s_{P,n}e^{j{\phi}_n}$. The WSR-E region can be obtained through a rate maximization problem subject to transmit power and output DC current constraints
		\begin{maxi}
			% {\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{\Theta}_0,\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert{(h_{D,n}+\boldsymbol{h}_{R,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})w_{I,n}}\rvert^2}{\sigma_n^2}\right)}}{\label{op:1}}{}
			{\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{v},\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert(h_{D,n}+\boldsymbol{\Phi}_n^H\boldsymbol{v})w_{I,n}\rvert^2}{\sigma_n^2}\right)}}{\label{op:1}}{}
			\addConstraint{\frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P})\le{P}}
			\addConstraint{z(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{v},\rho)\ge{\bar{z}}}
			\addConstraint{\lvert{v_l}\rvert=1,\quad l=1,\dots,L}
			% \addConstraint{0\le{\theta_l}\le{2{\pi}},\quad l=1,\dots,L}
		\end{maxi}
		Problem \ref{op:1} is intricate due to the non-convex rate function, unit-modulus constraint, and non-convex DC current requirement with coupled variables.

		\begin{subsubsection}{Frequency-Selective IRS}
			In frequency-selective IRS, each element is expected to provide adjustable subband-dependent reflection coefficients such that the total degree of freedom (DoF) of IRS is $NL$. Therefore, $\boldsymbol{v}_n$ replaces $\boldsymbol{v}$ in \ref{op:1}. Note that $\lvert{(h_{D,n}+\boldsymbol{\Phi}_n^H\boldsymbol{v}_n)w_{I,n}}\rvert \le \lvert{h_{D,n}w_{I,n}}\rvert+\lvert{\boldsymbol{\Phi}_n^H\boldsymbol{v}_nw_{I,n}}\rvert$ where the equality holds if and only if the direct and IRS-aided links are aligned by
			\begin{equation}
				\theta_{n,l}^\star = \angle{h}_{D,n} - \angle{h_{R,n,l}}-\angle{h_{I,n,l}}
			\end{equation}
			That is to say, the optimal phase shift is obtained in closed form in the single-user scenario. On top of this, it can be observed from \ref{eq:gamma_{k,n}}, \ref{eq:R_k} and \ref{eq:z_k_truncated} that the optimal phase of information and power waveforms are matched to composite frequency response as
			\begin{equation}\label{eq:phi_n}
				\phi_{I,n}^\star=\phi_{P,n}^\star=-\bar{\psi}_n
			\end{equation}
			With all the phases determined, the original problem \ref{op:1} is reduced to
			\begin{maxi}
				% {\boldsymbol{s}_I,\boldsymbol{s}_P,\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)(A_{D,n}+\boldsymbol{A}_{R,n}\boldsymbol{A}_{I,n})^2{s_{I,n}^2}}{\sigma_n^2}\right)}}{\label{op:2}}{}
				{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)A_n^2{s_{I,n}^2}}{\sigma_n^2}\right)}}{\label{op:2}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P})\le{P}}
				\addConstraint{z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)\ge{\bar{z}}}
			\end{maxi}
			\begin{figure*}[b]
				\hrule
				\begin{equation}\label{eq:z_gp}
					\begin{split}
						z
						&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}\sum_n{A_n^2(s_{I,n}^2+s_{P,n}^2)}+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}{A_{n_1}A_{n_2}A_{n_3}A_{n_4}(2s_{I,n_1}s_{I,n_2}s_{I,n_3}s_{I,n_4}+s_{P,n_1}s_{P,n_2}s_{P,n_3}s_{P,n_4})}\\
						&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_n{{A_n^4}{s_{I,n}^2}{s_{P,n}^2}}
					\end{split}
				\end{equation}
			\end{figure*}
			with $z$ given by \ref{eq:z_gp}. It can be transformed to an equivalent problem by introducing an auxiliary variable $t_0$
			\begin{mini}
				{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho}{\frac{1}{t_0}}{\label{op:3}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P})\le{P}}
				\addConstraint{\frac{t_0}{\prod_{n}{\left(1+\frac{(1-\rho){A_n^2}{s_{I,n}^2}}{\sigma_n^2}\right)}}\le{1}}
				\addConstraint{\frac{\bar{z}}{z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}\le{1}}
			\end{mini}
			\ref{op:3} is a Reversed Geometric Program which can be transformed to standard Geometric Program (GP). The basic idea is to decompose the information and power posynomials as sum of monomials, then derive their upper bounds using Arithmetic Mean-Geometric Mean (AM-GM) inequality \cite{Clerckx2018b,Chiang2005}. Let $z(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)=\sum_{{m_P}=1}^{M_P}{g_{P,m_P}(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}$, problem \ref{op:3} is equivalent to
			% $1+\bar{\rho}{A_n^2}{s_{I,n}^2}/\sigma_n^2=\sum_{{m_{I,n}}=1}^{M_{I,n}}{g_{I,m_{I,n}}(\boldsymbol{s}_I,\bar{\rho})}$
			\begin{mini}
				{\boldsymbol{s}_I,\boldsymbol{s}_P,\rho}{\frac{1}{t_0}}{\label{op:4}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{s}_I^H}{\boldsymbol{s}_I}+{\boldsymbol{s}_P^H}{\boldsymbol{s}_P})\le{P}}
				\addConstraint{{t_0}\prod_{n}{\left(\frac{1}{\gamma_{I,n,1}}\right)^{-\gamma_{I,n,1}} \left(\frac{\bar{\rho}{A_n^2}{s_{I,n}^2}}{{\sigma_n^2}{\gamma_{I,n,2}}}\right)^{-\gamma_{I,n,2}}}\le{1}}
				\addConstraint{\bar{z}\prod_{m_P}{\left(\frac{g_{P,m_P}(\boldsymbol{s}_I,\boldsymbol{s}_P,\rho)}{\gamma_{P,m_P}}\right)^{-\gamma_{P,m_P}}}\le{1}}
				\addConstraint{\rho+\bar{\rho}\le{1}}
			\end{mini}
			where $\gamma_{I,n,1},\gamma_{I,n,2} \ge 0$, $\gamma_{I,n,1}+\gamma_{I,n,2}=1$, $\gamma_{P,m_P} \ge 0,\forall m_P=1,\dots,M_P$ and $\sum_{{m_P}=1}^{M_P}{\gamma_{m_P}}=1$. As suggested in \cite{Clerckx2018b}, the tightness of the AM-GM inequality depends on $\{\gamma_{I,n},\gamma_P\}$ that require iterative update. At iteration $i$, we choose
			\begin{align}
				\gamma_{I,n,1}^{(i)} & =\frac{1}{1+\frac{\bar{\rho}^{(i-1)}{A_n^2}{s_{I,n}^{(i-1)}}^2}{\sigma_n^2}},                                                                         &  & n=1,\dots,N,    \\
				\gamma_{I,n,2}^{(i)} & =\frac{\frac{\bar{\rho}^{(i-1)}{A_n^2}{s_{I,n}^{(i-1)}}^2}{\sigma_n^2}}{1+\frac{\bar{\rho}^{(i-1)}{A_n^2}{s_{I,n}^{(i-1)}}^2}{\sigma_n^2}},           &  & n=1,\dots,N,    \\
				\gamma_{P,m_P}^{(i)} & =\frac{g_{P,m_P}(\boldsymbol{s}_I^{(i-1)},\boldsymbol{s}_P^{(i-1)},\rho^{(i-1)})}{z(\boldsymbol{s}_I^{(i-1)},\boldsymbol{s}_P^{(i-1)},\rho^{(i-1)})}, &  & m_P=1,\dots,M_P
			\end{align}
			and then solve problem \ref{op:4}.
		\end{subsubsection}

		\begin{subsubsection}{Frequency-Flat IRS}
			In contrast, frequency-flat IRS reflects all subbands equally with a DoF of $L$. We observe that
			\begin{equation}
				\begin{split}
					\lvert{h_{D,n}+\boldsymbol{\Phi}_n^H\boldsymbol{v}}\rvert^2
					&=\lvert{h_{D,n}}\rvert^2+h_{D,n}^*\boldsymbol{\Phi}_n^H\boldsymbol{v}+\boldsymbol{v}^H\boldsymbol{\Phi}_n{h_{D,n}}+\boldsymbol{v}^H\boldsymbol{\Phi}\boldsymbol{\Phi}^H\boldsymbol{v}\\
					&=\bar{\boldsymbol{v}}^H\boldsymbol{R}\bar{\boldsymbol{v}}=\mathrm{Tr}(\boldsymbol{R}_n\bar{\boldsymbol{v}}\bar{\boldsymbol{v}}^H)=\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{V})
				\end{split}
			\end{equation}
			where $t$ is an auxiliary variable with unit modulus and
			\begin{equation}
				\boldsymbol{R}_n=
				\begin{bmatrix}
					\boldsymbol{\Phi}_n\boldsymbol{\Phi}_n^H & \boldsymbol{\Phi}_n{h_{D,n}} \\
					h_{D,n}^*{\boldsymbol{\Phi}_n^H}         & h_{D,n}^*{h_{D,n}}
				\end{bmatrix},
				\quad \bar{\boldsymbol{v}}=\
				\begin{bmatrix}
					\boldsymbol{v} \\
					t
				\end{bmatrix},
				\quad \bar{\boldsymbol{V}}=\bar{\boldsymbol{v}}\bar{\boldsymbol{v}}^H
			\end{equation}
			Hence, \ref{op:1} is transformed to
			\begin{maxi}
				{\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{V},\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert{w}_{I,n}\rvert^2\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{V})}{\sigma_n^2}\right)}}{\label{op:temp3}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P})\le{P}}
				\addConstraint{z(\boldsymbol{w}_I,\boldsymbol{w}_P,\boldsymbol{V},\rho)\ge{\bar{z}}}
				\addConstraint{\boldsymbol{V}_{l,l}=1,l=1,\dots,L+1}
				\addConstraint{\boldsymbol{V}\succeq{0}}
				\addConstraint{\mathrm{rank}(\boldsymbol{V})=1}
			\end{maxi}
			To reduce the design complexity, we propose an suboptimal alternating optimization algorithm that iteratively updates the phase shifts and the waveforms with the other being fixed.

			% ? AO: optimize phase shifts with given waveform
			The phase optimization subproblem is formed as follows. For a given waveform $\boldsymbol{w}_I,\boldsymbol{w}_P,\rho$, problem \ref{op:temp3} reduces to
			\begin{maxi}
				{\boldsymbol{V}}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert{w}_{I,n}\rvert^2\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{V})}{\sigma_n^2}\right)}}{\label{op:temp4}}{}
				\addConstraint{z(\boldsymbol{V})\ge{\bar{z}}}
				\addConstraint{\boldsymbol{V}_{l,l}=1,l=1,\dots,L+1}
				\addConstraint{\boldsymbol{V}\succeq{0}}
				\addConstraint{\mathrm{rank}(\boldsymbol{V})=1}
			\end{maxi}
			To tackle the non-convex current constraint, we collect the channel matrices into $\boldsymbol{\Phi}^H=[\boldsymbol{\Phi}_1,\dots,\boldsymbol{\Phi}_N]^H \in \mathbb{C}^{N \times L}$ and $\boldsymbol{h}=\boldsymbol{h}_D+\boldsymbol{\Phi}^H\boldsymbol{v} \in \mathbb{C}^{N \times 1}$. The fixed waveform matrices are defined as $\boldsymbol{M}_{I/P}=\boldsymbol{w}_{I/P}^*\boldsymbol{w}_{I/P}^T$. On top of this, let $\boldsymbol{M}_{I/P, n}$ keep the $n$-th ($n=-N+1,\dots,N-1$) diagonal of $\boldsymbol{M}_{I/P}$ and null the remaining entries. Due to the positive definiteness of $\boldsymbol{M}_{I/P}$, we have $\boldsymbol{M}_{I/P,-n}=\boldsymbol{M}_{I/P,n}^H$. Hence, the output current expression \ref{eq:z_k_truncated} is transformed to \ref{eq:z_k_irs}.
			\begin{figure*}[b]
				\hrule
				\begin{equation}\label{eq:z_k_irs}
					\begin{split}
						z
						&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(\boldsymbol{h}^H\boldsymbol{M}_{I,0}\boldsymbol{h}+\boldsymbol{h}^H\boldsymbol{M}_{P,0}\boldsymbol{h})\\
						% &\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\left({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I)^H+{\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P({\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P)^H\right)
						% &\quad+\frac{3}{4}{k_4}{\rho^2}{R_{\text{ant}}^2}\left({\boldsymbol{w}_I^H\boldsymbol{M}_n}\boldsymbol{w}_I({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I)^H+{\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P({\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P)^H\right)
						&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{n=-N+1}^{N-1}{2(\boldsymbol{h}^H\boldsymbol{M}_{I,n}\boldsymbol{h})(\boldsymbol{h}^H\boldsymbol{M}_{I,n}\boldsymbol{h})^*+(\boldsymbol{h}^H\boldsymbol{M}_{P,n}\boldsymbol{h})(\boldsymbol{h}^H\boldsymbol{M}_{P,n}\boldsymbol{h})^*}\\
						&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}{(\boldsymbol{h}^H\boldsymbol{M}_{I,0}\boldsymbol{h})(\boldsymbol{h}^H\boldsymbol{M}_{P,0}\boldsymbol{h})}
					\end{split}
				\end{equation}
			\end{figure*}
			We further simplify it by introducing auxiliary variables
			\begin{equation}\label{eq:t}
				\begin{split}
					t_{I/P,n}
					&=\boldsymbol{h}^H\boldsymbol{M}_{I/P,n}\boldsymbol{h}\\
					&=\mathrm{Tr}(\boldsymbol{h}\boldsymbol{h}^H\boldsymbol{M}_{I/P,n})\\
					&=\mathrm{Tr}(\boldsymbol{R}^H\boldsymbol{V}\boldsymbol{R}\boldsymbol{M}_{I/P,n})\\
					&=\mathrm{Tr}(\boldsymbol{R}\boldsymbol{M}_{I/P,n}\boldsymbol{R}^H\boldsymbol{V})\\
					&=\mathrm{Tr}(\boldsymbol{C}_{I/P,n}\boldsymbol{V})
				\end{split}
			\end{equation}
			where $\boldsymbol{R}^H=[\boldsymbol{\Phi}^H,\boldsymbol{h}_D] \in \mathbb{C}^{N \times (L+1)}$ and $\boldsymbol{C}_{I/P,n}=\boldsymbol{R}\boldsymbol{M}_{I/P,n}\boldsymbol{R}^H \in \mathbb{C}^{(L+1)\times(L+1)}$. Therefore, \ref{eq:z_k_irs} rewrites as
			\begin{equation}\label{eq:z_k_irs_t}
				\begin{split}
					z
					&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(t_{I,0}+t_{P,0})\\
					&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{n=-N+1}^{N-1}{2t_{I,n}t_{I,n}^*+t_{P,n}t_{P,n}^*}\\
					&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}t_{I,0}t_{P,0}
				\end{split}
			\end{equation}

			% It holds that $t_{I/P,n}^*t_{I/P,n}=t_{I/P,-n}^*t_{I/P,-n}$ since $\boldsymbol{M}_{I/P,-n}=\boldsymbol{M}_{I/P,n}^H$. On top of this, denote $\boldsymbol{t}_{I/P}=[t_{I/P,1},\dots,t_{I/P,N-1}]^T \in \mathbb{C}^{(N-1) \times 1}$ and rewrite \ref{eq:z_k_irs} as
			% \begin{equation}\label{eq:z_k_irs_t}
			% 	\begin{split}
			% 		z
			% 		&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(t_{I,0}+t_{P,0})\\
			% 		&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}(2t_{I,0}^*t_{I,0}+t_{P,0}^*t_{P,0}+4\boldsymbol{t}_I^H\boldsymbol{t}_I+2\boldsymbol{t}_P^H\boldsymbol{t}_P)\\
			% 		&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}t_{I,0}t_{P,0}
			% 	\end{split}
			% \end{equation}
			We use first-order Taylor expansion to approximate the second-order terms in \ref{eq:z_k_irs_t}. Based on the variables optimized at iteration $k - 1$, the local approximations at iteration $k$ are \cite{Adali2010}
			\begin{equation}
				\begin{split}
					t_{I/P,n}^{(k)} (t_{I/P,n}^{(k)})^*
					& \approx 2 \Re\left\{t_{I/P,n}^{(k)} (t_{I/P,n}^{(k-1)})^*\right\} - t_{I/P,n}^{(k-1)} (t_{I/P,n}^{(k-1)})^* \\
					& = 2 \Re \left\{\mathrm{Tr}\left((t_{I/P,n}^{(k-1)})^*\boldsymbol{C}_{I/P,n}\boldsymbol{V}^{(k)}\right)\right\} - t_{I/P,n}^{(k-1)} (t_{I/P,n}^{(k-1)})^*\\
					& = \mathrm{Tr}\left((t_{I/P,n}^{(k-1)})^*\boldsymbol{C}_{I/P,n}\boldsymbol{V}^{(k)}\right) + \mathrm{Tr}(t_{I/P,n}^{(k-1)}\boldsymbol{C}_{I/P,n}^H\boldsymbol{V}^{(k)})\\
					& \quad- t_{I/P,n}^{(k-1)} (t_{I/P,n}^{(k-1)})^*
				\end{split}
			\end{equation}
			and
			\begin{equation}
				\begin{split}
					t_{I,0}^{(k)} t_{P,0}^{(k)}
					& \approx t_{I,0}^{(k)} t_{P,0}^{(k-1)} + t_{I,0}^{(k-1)} t_{P,0}^{(k)} - t_{I,0}^{(k-1)} t_{P,0}^{(k-1)}\\
					& = \mathrm{Tr}(t_{P,0}^{(k-1)}\boldsymbol{C}_{I,0}\boldsymbol{V}^{(k)}) + \mathrm{Tr}(t_{I,0}^{(k-1)}\boldsymbol{C}_{P,0}\boldsymbol{V}^{(k)}) - t_{I,0}^{(k-1)} t_{P,0}^{(k-1)}
				\end{split}
			\end{equation}
			The second approximation holds since $t_{I/P,0}$ are real. Therefore, we have
			\begin{equation}\label{eq:z_irs_approx}
				\begin{split}
					\tilde{z}(\boldsymbol{V}^{(k)})
					& = \mathrm{Tr}(\boldsymbol{A}^{(k)}\boldsymbol{V}^{(k)}) \\
					& - \frac{3 k_4 \rho^2 R_{\text{ant}}^2}{8} \sum_{n=-N+1}^{N-1} 2t_{I,n}^{(k-1)} (t_{I,n}^{(k-1)})^* + t_{P,n}^{(k-1)} (t_{P,n}^{(k-1)})^* \\
					& - \frac{3{k_4}{\rho^2}{R_{\text{ant}}^2}}{2} t_{I,0}^{(k-1)} t_{P,0}^{(k-1)}
				\end{split}
			\end{equation}
			where the Hermitian matrix $\boldsymbol{A}^{(k)}$ is
			\begin{equation}\label{eq:A_k}
				\begin{split}
					\boldsymbol{A}^{(k)}
					& = \frac{k_2 \rho R_{\text{ant}}}{2}(\boldsymbol{C}_{I,0}+\boldsymbol{C}_{P,0})\\
					& \quad+ \frac{3 k_4 \rho^2 R_{\text{ant}}^2}{8}\sum_{n=-N+1}^{N-1} 2\left((t_{I,n}^{(k-1)})^*\boldsymbol{C}_{I,n} + t_{I,n}^{(k-1)}\boldsymbol{C}_{I,n}^H\right)\\
					& \quad \quad + \left((t_{P,n}^{(k-1)})^*\boldsymbol{C}_{P,n} + t_{P,n}^{(k-1)}\boldsymbol{C}_{P,n}^H\right)\\
					& \quad+ \frac{3{k_4}{\rho^2}{R_{\text{ant}}^2}}{2} (t_{P,0}^{(k-1)}\boldsymbol{C}_{I,0} + t_{I,0}^{(k-1)}\boldsymbol{C}_{P,0})
				\end{split}
			\end{equation}
			Plug \ref{eq:z_irs_approx} into problem \ref{op:temp4} and solve it by iterative interior-point method. Denote the optimal IRS matrix as $\boldsymbol{V}^{\star}$. If $\mathrm{rank}(\boldsymbol{V}^{\star})=1$, the optimal phase shift vector $\bar{\boldsymbol{v}}^\star$ is attained by eigenvalue decomposition (EVD). Otherwise, a best feasible candidate $\bar{\boldsymbol{v}}^\star$ can be extracted through Gaussian randomization method \cite{Huang2010}. First, we perform EVD on $\boldsymbol{V}^{\star}$ as $\boldsymbol{V}^{\star}=\boldsymbol{U}_{\boldsymbol{V}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{V}^{\star}}\boldsymbol{U}_{\boldsymbol{V}^{\star}}^H$. Then, we generate $R$ random CSCG vectors $\boldsymbol{r}_r \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{L+1}),\ r=1,\dots,R$ and construct the corresponding candidates $\bar{\boldsymbol{v}}_r=\boldsymbol{U}_{\boldsymbol{V}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{V}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_r$. Next, the optimal solution $\bar{\boldsymbol{v}}^\star$ is approximated by the one achieving maximum objective value of \ref{op:temp4}. Finally, we can retrieve the phase shift as $\theta_l=\arg(v_l^\star/v_{L+1}^\star)$. The algorithm for the phase optimization subproblem is summarized in Algorithm \ref{alg:irs}.

			\begin{algorithm}
				\caption{IRS Optimization}
				\label{alg:irs}
				\begin{algorithmic}[1]
					\State \textbf{Input} $\boldsymbol{w}_I,\boldsymbol{w}_P,\rho$
					\State \textbf{Initialize} $k=0$, $\boldsymbol{V}^{(0)}$, $t_{I/P,n}^{(0)} \ \forall n$
					\Repeat
					\State $k = k + 1$
					\State Update SDR matrix $\boldsymbol{A}^{(k)}$ by \ref{eq:A_k}
					\State Obtain IRS matrix $\boldsymbol{V}^{(k)}$ by solving problem \ref{op:temp4}
					\State Update auxiliary $t_{I/P,n}^{(k)} \forall n$ by \ref{eq:t} for SCA
					% \Until $\lVert \boldsymbol{V}^{(k)} - \boldsymbol{V}^{(k - 1)} \rVert_F / \lVert \boldsymbol{V}^{(k)} \rVert_F \le \epsilon$
					\Until $R^{(k)}-R^{(k-1)} \le \epsilon$
					\State Generate CSCG random vectors $\boldsymbol{r}_r \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{L+1}) \ \forall r$
					\State Perform EVD $\boldsymbol{V}^{\star}=\boldsymbol{U}_{\boldsymbol{V}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{V}^{\star}}\boldsymbol{U}_{\boldsymbol{V}^{\star}}^H$
					\State Construct candidate IRS vectors $\bar{\boldsymbol{v}}_r=\boldsymbol{U}_{\boldsymbol{V}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{V}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_r \forall r$ and corresponding matrices $\boldsymbol{V}_r=\bar{\boldsymbol{v}}_r\bar{\boldsymbol{v}}_r^H  \ \forall r$
					\State Select the best solution $\boldsymbol{V}_r^\star$ for problem \ref{op:temp4} and corresponding $\boldsymbol{v}_r^\star$
					\State Compute IRS phase shift by $\theta_l=\arg(v_l^\star/v_{L+1}^\star) \ \forall l$
					\State \textbf{Output} $\theta_l, l = 1 , \dots L$
				\end{algorithmic}
			\end{algorithm}

			The waveform optimization subproblem is formed as follows. For a given $\boldsymbol{V}$, problem \ref{op:temp3} reduces to
			\begin{maxi}
				{\boldsymbol{w}_I,\boldsymbol{w}_P,\rho}{\sum_{n}{\log_2\left(1+\frac{(1-\rho)\lvert{w}_{I,n}\rvert^2\mathrm{Tr}(\boldsymbol{R}_n\boldsymbol{V})}{\sigma_n^2}\right)}}{\label{op:temp5}}{}
				\addConstraint{\frac{1}{2}({\boldsymbol{w}_I^H}{\boldsymbol{w}_I}+{\boldsymbol{w}_P^H}{\boldsymbol{w}_P})\le{P}}
				\addConstraint{z(\boldsymbol{w}_I,\boldsymbol{w}_P,\rho)\ge{\bar{z}}}
			\end{maxi}
			Similarly, define $\boldsymbol{M}=\boldsymbol{h}^*\boldsymbol{h}^T$ and let $\boldsymbol{M}_n$ keep the $n$-th ($n=-N+1,\dots,N-1$) diagonal of $\boldsymbol{M}$ and null the remaining entries. Since $\boldsymbol{M} \succ 0$, we have $\boldsymbol{M}_{-n}=\boldsymbol{M}_n^H$. Hence, \ref{eq:z_k_truncated} is transformed to \ref{eq:z_k_waveform}.
			\begin{figure*}[b]
				\hrule
				\begin{equation}\label{eq:z_k_waveform}
					\begin{split}
						z
						&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(\boldsymbol{w}_I^H\boldsymbol{M}_0\boldsymbol{w}_I+\boldsymbol{w}_P^H\boldsymbol{M}_0\boldsymbol{w}_P)\\
						&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{n=-N+1}^{N-1}{2(\boldsymbol{w}_I^H\boldsymbol{M}_{n}\boldsymbol{w}_I)(\boldsymbol{w}_I^H\boldsymbol{M}_{n}\boldsymbol{w}_I)^*+(\boldsymbol{w}_P^H\boldsymbol{M}_{n}\boldsymbol{w}_P)(\boldsymbol{w}_P^H\boldsymbol{M}_{n}\boldsymbol{w}_P)^*}\\
						&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}{(\boldsymbol{w}_I^H\boldsymbol{M}_{0}\boldsymbol{w}_I)(\boldsymbol{w}_P^H\boldsymbol{M}_{0}\boldsymbol{w}_P)}
					\end{split}
				\end{equation}
			\end{figure*}
			Introduce auxiliary variables
			\begin{equation}\label{eq:t'}
				\begin{split}
					t'_{I/P,n}
					& = \boldsymbol{w}_{I/P}^H\boldsymbol{M}_{n}\boldsymbol{w}_{I/P}\\
					& = \mathrm{Tr}(\boldsymbol{M}_{n}\boldsymbol{w}_{I/P}\boldsymbol{w}_{I/P}^H)\\
					& = \mathrm{Tr}(\boldsymbol{M}_{n}\boldsymbol{W}_{I/P})
				\end{split}
			\end{equation}
			where $\boldsymbol{W}_{I/P}=\boldsymbol{w}_{I/P}\boldsymbol{w}_{I/P}^H$. Therefore, \ref{eq:z_k_waveform} rewrites as
			\begin{equation}\label{eq:z_k_waveform_t}
				\begin{split}
					z
					&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(t'_{I,0}+t'_{P,0})\\
					&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{n=-N+1}^{N-1}{2t'_{I,n}t_{I,n}^{\prime \ *}+t'_{P,n}t_{P,n}^{\prime \ *}}\\
					&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}t'_{I,0}t'_{P,0}
				\end{split}
			\end{equation}
			At iteration $k$, the second-order terms are approximated by first-order Taylor series as
			\begin{equation}
				\begin{split}
					t_{I/P,n}^{\prime \ (k)} (t_{I/P,n}^{\prime \ (k)})^*
					& \approx 2 \Re\left\{t_{I/P,n}^{\prime \ (k)} (t_{I/P,n}^{\prime (k-1)})^*\right\} - t_{I/P,n}^{\prime (k-1)} (t_{I/P,n}^{\prime (k-1)})^* \\
					& = 2 \Re \left\{\mathrm{Tr}((t_{I/P,n}^{\prime (k-1)})^*\boldsymbol{M}_{n}\boldsymbol{W}_{I/P}^{(k)})\right\} - t_{I/P,n}^{\prime (k-1)} (t_{I/P,n}^{\prime (k-1)})^*\\
					& = \mathrm{Tr}\left((t_{I/P,n}^{\prime (k-1)})^*\boldsymbol{M}_{n}\boldsymbol{W}_{I/P}^{(k)}\right) + \mathrm{Tr}(t_{I/P,n}^{\prime (k-1)}\boldsymbol{M}_{n}^H\boldsymbol{W}_{I/P}^{(k)})\\
					& \quad- t_{I/P,n}^{\prime (k-1)} (t_{I/P,n}^{\prime (k-1)})^*
				\end{split}
			\end{equation}
			and
			\begin{equation}
				\begin{split}
					t_{I,0}^{\prime \ (k)} t_{P,0}^{\prime \ (k)}
					& \approx t_{I,0}^{\prime \ (k)} t_{P,0}^{\prime (k-1)} + t_{I,0}^{\prime (k-1)} t_{P,0}^{\prime \ (k)} - t_{I,0}^{\prime (k-1)} t_{P,0}^{\prime (k-1)}\\
					& = \mathrm{Tr}\left(t_{P,0}^{\prime (k-1)}\boldsymbol{M}_{0}\boldsymbol{W}_{I,0}^{(k)}\right) + \mathrm{Tr}(t_{I,0}^{\prime (k-1)}\boldsymbol{M}_{0}\boldsymbol{W}_{P,0}^{(k)}) - t_{I,0}^{\prime (k-1)} t_{P,0}^{\prime (k-1)}
				\end{split}
			\end{equation}
			Therefore, we have
			\begin{equation}\label{eq:z_waveform_approx}
				\begin{split}
					\tilde{z}(\boldsymbol{W}_I^{(k)},\boldsymbol{W}_P^{(k)},\rho^{(k-1)})
					& = \mathrm{Tr}(\boldsymbol{A}_I^{(k)}\boldsymbol{W}_I^{(k)}) + \mathrm{Tr}(\boldsymbol{A}_P^{(k)}\boldsymbol{W}_P^{(k)}) \\
					& - \frac{3 k_4 (\rho^{(k-1)})^2 R_{\text{ant}}^2}{8} \sum_{n=-N+1}^{N-1} 2t_{I,n}^{\prime (k-1)} (t_{I,n}^{\prime (k-1)})^* + t_{P,n}^{\prime (k-1)} (t_{P,n}^{\prime (k-1)})^* \\
					& - \frac{3{k_4}{(\rho^{(k-1)})^2}{R_{\text{ant}}^2}}{2} t_{I,0}^{\prime (k-1)} t_{P,0}^{\prime (k-1)}
				\end{split}
			\end{equation}
			where the Hermitian matrices $\boldsymbol{A}_I^{(k)}$ and $\boldsymbol{A}_P^{(k)}$ are
			\begin{equation}\label{eq:A_I,k}
				\begin{split}
					\boldsymbol{A}_I^{(k)}
					& = \frac{k_2 \rho^{(k-1)} R_{\text{ant}}}{2}\boldsymbol{M}_0 \\
					& + \frac{3 k_4 (\rho^{(k-1)})^2 R_{\text{ant}}^2}{8} \sum_{n=-N+1}^{N-1} 2\left((t_{I,n}^{\prime (k-1)})^*\boldsymbol{M}_{n} + t_{I,n}^{\prime (k-1)}\boldsymbol{M}_{n}^H\right) \\
					& + \frac{3{k_4}{(\rho^{(k-1)})^2}{R_{\text{ant}}^2}}{2} t_{P,0}^{\prime (k-1)}\boldsymbol{M}_{0}
				\end{split}
			\end{equation}
			\begin{equation}\label{eq:A_P,k}
				\begin{split}
					\boldsymbol{A}_P^{(k)}
					& = \frac{k_2 \rho^{(k-1)} R_{\text{ant}}}{2}\boldsymbol{M}_0 \\
					& + \frac{3 k_4 (\rho^{(k-1)})^2 R_{\text{ant}}^2}{8} \sum_{n=-N+1}^{N-1} (t_{P,n}^{\prime (k-1)})^*\boldsymbol{M}_{n} + t_{P,n}^{\prime (k-1)}\boldsymbol{M}_{n}^H \\
					& + \frac{3{k_4}{(\rho^{(k-1)})^2}{R_{\text{ant}}^2}}{2} t_{I,0}^{\prime (k-1)}\boldsymbol{M}_{0}
				\end{split}
			\end{equation}
			Plug \ref{eq:z_waveform_approx} into problem \ref{op:temp5} and solve it by iterative interior-point method. Given the optimal waveform matrices $\boldsymbol{W}_I$ and $\boldsymbol{W}_P$, the best rank-1 solution $\boldsymbol{w}_I$ and $\boldsymbol{w}_P$ can be obtained through randomization method. Details are omitted here. The algorithm for the waveform optimization subproblem is summarized in Algorithm ~.

			\begin{algorithm}
				\caption{Waveform Optimization}
				\label{alg:waveform}
				\begin{algorithmic}[1]
					\State \textbf{Input} $\boldsymbol{V}$
					\State \textbf{Initialize} $k=0$, $\boldsymbol{w}_{I/P}^{(0)}$, $\rho^{(0)}$, $t_{I/P,n}^{\prime (0)} \ \forall n$
					\Repeat
					\State $k = k + 1$
					\State Update SDR matrices $\boldsymbol{A}_{I/P}^{(k)}$ by \ref{eq:A_I,k} and \ref{eq:A_P,k}
					\State Obtain waveform matrices $\boldsymbol{W}_{I/P}^{(k)}$ and $\rho^{(k)}$ by solving problem \ref{op:temp5}
					\State Update auxiliary $t_{I/P,n}^{\prime (k)} \forall n$ by \ref{eq:t'} for SCA
					% \Until $\lVert \boldsymbol{W}_I^{(k)} - \boldsymbol{W}_I^{(k - 1)} \rVert_F / \lVert \boldsymbol{W}_I^{(k)} \rVert_F \le \epsilon$
					\Until $R^{(k)}-R^{(k-1)} \le \epsilon$
					\State Generate CSCG random vectors $\boldsymbol{r}_r \sim \mathcal{CN}(\boldsymbol{0},\boldsymbol{I}_{N}) \ \forall r$
					\State Perform EVD $\boldsymbol{W}_{I/P}^{\star}=\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}^H$
					\State Construct candidate waveform vectors $\boldsymbol{w}_{I/P,r}=\boldsymbol{U}_{\boldsymbol{W}_{I/P}^{\star}}\boldsymbol{\Sigma}_{\boldsymbol{W}_{I/P}^{\star}}^{\frac{1}{2}}\boldsymbol{r}_r \ \forall r$ and corresponding matrices $\boldsymbol{W}_{I/P,r}=\boldsymbol{w}_{I/P,r}\boldsymbol{w}_{I/P,r}^H  \ \forall r$
					\State Select the best solution pair $\boldsymbol{W}_{I,r}^\star, \boldsymbol{W}_{P,r}^\star$ for problem \ref{op:temp5} and corresponding $\boldsymbol{w}_{I,r}^\star, \boldsymbol{w}_{P,r}^\star$
					\State \textbf{Output} $\boldsymbol{w}_I^\star, \boldsymbol{w}_P^\star, \rho^\star$
				\end{algorithmic}
			\end{algorithm}


			% * It holds that $\boldsymbol{M}_{I/P,0} \succeq 0$ and $\boldsymbol{M}_{I/P,-n}=\boldsymbol{M}_{I/P,n}^H$ for $n{\ne}0$.

			% To tackle the non-convex current constraint, we expand and rewrite the coupled channel terms in \ref{eq:z_k_truncated} as
			% \begin{equation}
			% 	\begin{split}
			% 		{h_{n_3}^*}{h_{n_1}}
			% 		&=(h_{D,n_3}^*+\boldsymbol{\Phi}_{n_3}^T\boldsymbol{v}^*)(h_{D,n_1}+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_1}^*})\\
			% 		&={h_{D,n_1}}{h_{D,n_3}^*}+{h_{D,n_1}}\boldsymbol{\Phi}_{n_3}^T\boldsymbol{v}^*+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_1}^*}h_{D,n_3}^*+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_1}^*}\boldsymbol{\Phi}_{n_3}^T\boldsymbol{v}^*\\
			% 		&=\bar{\boldsymbol{v}}^T\boldsymbol{R}_{n_3,n_1}\bar{\boldsymbol{v}}^*\\
			% 		&=\mathrm{Tr}(\boldsymbol{R}_{n_3,n_1}\boldsymbol{V}^*)
			% 	\end{split}
			% \end{equation}
			% where
			% \begin{equation}
			% 	\boldsymbol{R}_{n_3,n_1}=
			% 	\begin{bmatrix}
			% 		\boldsymbol{\Phi}_{n_1}^*\boldsymbol{\Phi}_{n_3}^T & \boldsymbol{\Phi}_{n_1}^*{h_{D,n_3}^*} \\
			% 		h_{D,n_1}{\boldsymbol{\Phi}_{n_3}^T}               & h_{D,n_1}{h_{D,n_3}^*}
			% 	\end{bmatrix}
			% \end{equation}
			% Similarly, we have ${h_{n_4}^*}{h_{n_2}}=\mathrm{Tr}(\boldsymbol{R}_{n_4,n_2}\boldsymbol{V}^*)$ and ${h_n^*}{h_n}=\mathrm{Tr}(\boldsymbol{R}_{n,n}\boldsymbol{V}^*)$. Thus, \ref{eq:z_k_truncated} is equivalent to
			% \begin{figure*}[b]
			% 	\hrule
			% 	\begin{equation}\label{eq:z_k_su_temp}
			% 		\begin{split}
			% 			z
			% 			&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}\sum_n{\mathrm{Tr}(\boldsymbol{R}_{n,n}\boldsymbol{V}^*)(\boldsymbol{w}_{I,n}^H\boldsymbol{w}_{I,n}+\boldsymbol{w}_{P,n}^H\boldsymbol{w}_{P,n})}\\
			% 			&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{\substack{{n_1},{n_2},{n_3},{n_4}\\{n_1}+{n_2}={n_3}+{n_4}}}\mathrm{Tr}(\boldsymbol{R}_{n_3,n_1}\boldsymbol{V}^*)\mathrm{Tr}(\boldsymbol{R}_{n_4,n_2}\boldsymbol{V}^*)\left(2(\boldsymbol{w}_{I,n_3}^H\boldsymbol{w}_{I,n_1})(\boldsymbol{w}_{I,n_4}^H\boldsymbol{w}_{I,n_2})+(\boldsymbol{w}_{P,n_3}^H\boldsymbol{w}_{P,n_1})(\boldsymbol{w}_{P,n_4}^H\boldsymbol{w}_{P,n_2})\right)\\
			% 			&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_n{\mathrm{Tr}(\boldsymbol{R}_{n,n}\boldsymbol{V}^*)^2(\boldsymbol{w}_{I,n}^H\boldsymbol{w}_{I,n})(\boldsymbol{w}_{P,n}^H\boldsymbol{w}_{P,n})}
			% 		\end{split}
			% 	\end{equation}
			% \end{figure*}
		\end{subsubsection}


		% % ? AO: optimize weights with given phase shifts
		% To tackle the non-convex current constraint, we introduce a channel matrix $\boldsymbol{M}=\boldsymbol{h}^*\boldsymbol{h}^T \in \mathbb{C}^{N \times N}$ whose $(n_1,n_2)$ entry equals
		% \begin{equation}
		% 	\begin{split}
		% 		{h_{n_1}^*}{h_{n_2}}
		% 		&=(h_{D,n_1}^*+\boldsymbol{\Phi}_{n_1}^T\boldsymbol{v}^*)(h_{D,n_2}+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_2}^*})\\
		% 		&={h_{D,n_2}}{h_{D,n_1}^*}+{h_{D,n_2}}\boldsymbol{\Phi}_{n_1}^T\boldsymbol{v}^*+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_2}^*}h_{D,n_1}^*+\boldsymbol{v}^T{\boldsymbol{\Phi}_{n_2}^*}\boldsymbol{\Phi}_{n_1}^T\boldsymbol{v}^*\\
		% 		&=\bar{\boldsymbol{v}}^T\boldsymbol{R}_{n_1,n_2}\bar{\boldsymbol{v}}^*\\
		% 		&=\mathrm{Tr}(\boldsymbol{R}_{n_1,n_2}\boldsymbol{V}^*)
		% 	\end{split}
		% \end{equation}
		% where
		% \begin{equation}
		% 	\boldsymbol{R}_{n_1,n_2}=
		% 	\begin{bmatrix}
		% 		\boldsymbol{\Phi}_{n_2}^*\boldsymbol{\Phi}_{n_1}^T & \boldsymbol{\Phi}_{n_2}^*{h_{D,n_1}^*} \\
		% 		h_{D,n_2}{\boldsymbol{\Phi}_{n_1}^T}               & h_{D,n_2}{h_{D,n_1}^*}
		% 	\end{bmatrix}
		% \end{equation}
		% On top of this, $\boldsymbol{M}_n$ keeps the $n$-th ($n=-N+1,\dots,N-1$) diagonal of $\boldsymbol{M}$ and nulls the remaining entries. It holds that $\boldsymbol{M}_0 \succeq 0$ and $\boldsymbol{M}_{-n}=\boldsymbol{M}_{n}^H$ for $n{\ne}0$ \cite{Huang2017}. Therefore, \ref{eq:z_k_truncated} is transformed to \ref{eq:z_k_waveform}.
		% \begin{figure*}[b]
		% 	\hrule
		% 	\begin{equation}\label{eq:z_k_waveform}
		% 		\begin{split}
		% 			z
		% 			&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(\boldsymbol{w}_I^H\boldsymbol{M}_0\boldsymbol{w}_I+\boldsymbol{w}_P^H\boldsymbol{M}_0\boldsymbol{w}_P)\\
		% 			% &\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\left({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I)^H+{\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P({\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P)^H\right)
		% 			% &\quad+\frac{3}{4}{k_4}{\rho^2}{R_{\text{ant}}^2}\left({\boldsymbol{w}_I^H\boldsymbol{M}_n}\boldsymbol{w}_I({\boldsymbol{w}_I^H\boldsymbol{M}_0}\boldsymbol{w}_I)^H+{\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P({\boldsymbol{w}_P^H\boldsymbol{M}_0}\boldsymbol{w}_P)^H\right)
		% 			&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}\sum_{n=-N+1}^{N-1}{2(\boldsymbol{w}_I^H\boldsymbol{M}_n\boldsymbol{w}_I)(\boldsymbol{w}_I^H\boldsymbol{M}_n\boldsymbol{w}_I)^H+(\boldsymbol{w}_P^H\boldsymbol{M}_n\boldsymbol{w}_P)(\boldsymbol{w}_P^H\boldsymbol{M}_n\boldsymbol{w}_P)^H}\\
		% 			&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}{(\boldsymbol{w}_I^H\boldsymbol{M}_0\boldsymbol{w}_I)(\boldsymbol{w}_P^H\boldsymbol{M}_0\boldsymbol{w}_P)}
		% 		\end{split}
		% 	\end{equation}
		% \end{figure*}
		% We then introduce auxiliary vectors $\boldsymbol{t}_{I/P}=[t_{{I/P},0},\dots,t_{{I/P},N-1}]^T \in \mathbb{C}^{N \times 1}$ with $t_{{I/P},n}=\boldsymbol{w}_{I/P}^H\boldsymbol{M}_n\boldsymbol{w}_{I/P}=\mathrm{Tr}(\boldsymbol{M}_n\boldsymbol{W}_{I/P})$ and transform \ref{eq:z_k_waveform} to
		% % and define coefficient matrix $\boldsymbol{A}_0=\mathrm{diag}\{\}$
		% \begin{equation}\label{eq:z_k_su_compact}
		% 	\begin{split}
		% 		z
		% 		&=\frac{1}{2}{k_2}{\rho}{R_{\text{ant}}}(t_{I,0}+t_{P,0})\\
		% 		&\quad+\frac{3}{8}{k_4}{\rho^2}{R_{\text{ant}}^2}(4\boldsymbol{t}_I^H\boldsymbol{t}_I+2\boldsymbol{t}_P^H\boldsymbol{t}_P-2t_{I,0}t_{I,0}^*-t_{P,0}t_{P,0}^*)\\
		% 		&\quad+\frac{3}{2}{k_4}{\rho^2}{R_{\text{ant}}^2}t_{I,0}t_{P,0}
		% 	\end{split}
		% \end{equation}






		% A semidefinite programming (SDP) problem is then formulated by dropping the rank-one constraint


		% which can be solved by softwares as CVX \cite{Grant2013}. [Use random vector or rank reduction method to extract $\boldsymbol{v}$ from $\boldsymbol{V}$]
		% It leads to a local optimum and is sensitive to the initialization of $\Theta_0$, $\boldsymbol{w}_I$ and $\boldsymbol{w}_P$.
		% Moreover, a feasible phase design strategy that maximizes the effective composite channel is used for phase shift initialization.
		% Although the problem is non-convex, the target function can be reformulated using the triangle inequality
		% \begin{equation}
		% 	\lvert{(h_{D,n}+\boldsymbol{h}_{R,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n})w_{I,n}}\rvert \le \lvert{h_{D,n}w_{I,n}}\rvert+\lvert{\boldsymbol{h}_{R,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n}w_{I,n}}\rvert
		% \end{equation}
		% where the equality holds if and only if the direct and IRS-aided links align with each other. In such case, we have $A_n=A_{D,n}+\boldsymbol{A}_{R,n}\boldsymbol{A}_{I,n}$ and and $\bar{\psi}_n=\angle{h_{D,n}}=\angle{\boldsymbol{h}_{R,n}\boldsymbol{\Theta}_0\boldsymbol{h}_{I,n}}$. Therefore, the optimal phase shift at the $l$-th reflect element is obtained in closed form
		% \begin{equation}
		% 	\theta_l^\star=\angle{h_{D,n}}-\angle{h_{R,n,l}}-\angle{h_{I,n,l}}
		% \end{equation}
		% Besides, it can be concluded from \ref{eq:R_k} and \ref{eq:z_k_truncated} that the optimal information and power phases coincide at subband $n$, being matched to composite frequency response as
		% \begin{equation}\label{eq:phi_n}
		% 	\phi_{I,n}^\star=\phi_{P,n}^\star=-\bar{\psi}_n
		% \end{equation}


	\end{subsection}
\end{section}

\bibliographystyle{IEEEtran}
\bibliography{library.bib}
\end{document}
